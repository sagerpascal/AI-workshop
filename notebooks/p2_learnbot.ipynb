{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Workshop\n",
        "\n",
        "Erstellt von [Pascal Sager](http://sagerpascal.github.io) und dem [ZHAW Zentrum für Künstliche Intelligenz](https://www.zhaw.ch/de/engineering/institute-zentren/cai/)."
      ],
      "metadata": {
        "collapsed": false,
        "id": "77cd2e5bb9617e02"
      },
      "id": "77cd2e5bb9617e02"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation von Paketen\n",
        "\n",
        "Nachfolgender Code installiert fünf Python-Pakete: `langchain`, `pypdf`, `numpy`, `openai`, `sentence_transformers`, und `faiss-cpu`. Diese Pakete bieten verschiedene Funktionen, die im Kontext von künstlicher Intelligenz (KI) und maschinellem Lernen (ML) relevant sind. Durch die Nutzung von Paketen können wir Code von anderen Entwicklern wiederverwenden und müssen nicht alles selbst schreiben. Dies ist ein wichtiger Aspekt der Softwareentwicklung, da es uns ermöglicht, schneller zu arbeiten und Fehler zu vermeiden.\n",
        "\n",
        "##### Erklärung der Pakete\n",
        "\n",
        "1. **`langchain`**: Ein Paket, das möglicherweise spezifische Funktionen im Bereich der Sprachverarbeitung oder Textanalyse bereitstellt.\n",
        "\n",
        "2. **`pypdf`**: Ein Paket zur Bearbeitung von PDF-Dateien. Dies könnte in einem AI-Kontext nützlich sein, wenn Textinformationen aus PDFs extrahiert werden müssen.\n",
        "\n",
        "3. **`numpy`**: Ein weit verbreitetes Paket für numerische Berechnungen in Python. Wird oft in Kombination mit AI-Anwendungen verwendet, insbesondere für die Handhabung von Datenarrays und Matrizen.\n",
        "\n",
        "4. **`openai`**: Die OpenAI-Plattform bietet verschiedene AI-Modelle und Dienste an. Das Installieren des Pakets ermöglicht es, auf diese Ressourcen zuzugreifen und sie in eigenen Projekten zu verwenden.\n",
        "\n",
        "5. **`sentence_transformers`**: Ein Paket, das prätrainierte Modelle für die Generierung von Vektoren aus Sätzen bereitstellt. Dies kann für Aufgaben wie semantische Ähnlichkeitsberechnungen nützlich sein.\n",
        "\n",
        "6. **`faiss-cpu`**: Ein effizientes Indexierungs- und Suchpaket, das für das schnelle Durchsuchen großer Mengen von Vektoren optimiert ist. Kann in Anwendungen verwendet werden, die Ähnlichkeitsabfragen erfordern, wie sie in einigen AI- und ML-Szenarien vorkommen.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "92b8b877d8f884c7"
      },
      "id": "92b8b877d8f884c7"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.28)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.31)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.25)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.31)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.14.0)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (0.1.25)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.0.8 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install numpy\n",
        "!pip install openai\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:32:18.562881Z",
          "start_time": "2023-12-22T21:31:39.850388Z"
        },
        "id": "initial_id",
        "outputId": "d37685d2-2099-4a10-8946-5a47628ae20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "initial_id"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Import von Modulen\n",
        "Nach der Installation der Softwarepakete müssen diese importiert werden, um sie in Python verwenden zu können.\n",
        "Der nachfolgende Code importiert verschiedene Module aus dem `langchain`-Paket und einige zusätzliche Module wie `pathlib` und `random`. Diese Module bieten Funktionen und Werkzeuge, die für die Bearbeitung von Textdaten, die Verarbeitung von PDF-Dateien, die Erstellung von Chatmodellen und die Arbeit mit Embeddings relevant sind.\n",
        "\n",
        "##### Erklärung der Module\n",
        "\n",
        "1. **`ChatOpenAI`**: Ein Modul aus `langchain` für Chatmodelle basierend auf der OpenAI-GPT-Architektur. Dies ermöglicht die Implementierung von Chatbots oder ähnlichen Anwendungen.\n",
        "\n",
        "2. **`PromptTemplate`**: Ein Modul, das Vorlagen für Prompts (Aufforderungen) in Chatanwendungen bereitstellt. Prompts sind Anfragen oder Sätze, die an Chatmodelle gesendet werden, um eine spezifische Reaktion zu erhalten.\n",
        "\n",
        "3. **`StrOutputParser`**: Ein Modul, das die Ausgaben von Chatmodellen oder anderen Textgeneratoren auf die Konsole ermöglicht.\n",
        "\n",
        "4. **`RunnablePassthrough`**: Ein Modul, das für die Durchführung von Textoperationen oder -transformationen verwendet wird.\n",
        "\n",
        "5. **`HumanMessage`**: Ein Modul, das für die Erstellung von Nachrichtenobjekten verwendet wird, die an Chatmodelle gesendet werden können.\n",
        "\n",
        "6. **`BSHTMLLoader`**: Ein Modul, das Funktionen zum Laden von Text aus HTML-Dateien bereitstellt.\n",
        "\n",
        "7. **`RecursiveCharacterTextSplitter`**: Ein Modul, das sich wahrscheinlich auf die Aufteilung von Text in Abschnitte oder Absätze konzentriert. Dies könnte in Verbindung mit der Verarbeitung von großen Textdaten nützlich sein.\n",
        "\n",
        "8. **`HuggingFaceEmbeddings`**: Ein Modul für Embeddings, basierend auf Modellen von Hugging Face. Embeddings sind numerische Repräsentationen von Text, die in vielen AI-Anwendungen verwendet werden.\n",
        "\n",
        "9. **`FAISS`**: Ein Modul für die Integration von FAISS, einem effizienten Indexierungs- und Suchpaket, das oft in Zusammenhang mit Vektoren und Ähnlichkeitsabfragen verwendet wird.\n",
        "\n",
        "10. **`Path`**: Ein Modul aus der Standardbibliothek (`pathlib`), das Funktionen zum Arbeiten mit Dateipfaden bereitstellt.\n",
        "\n",
        "11. **`random`**: Ein Modul aus der Standardbibliothek (`random`), das Funktionen für Zufallsoperationen bereitstellt.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ae10f5177b24ecf"
      },
      "id": "ae10f5177b24ecf"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import StrOutputParser, HumanMessage\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain import FAISS\n",
        "from pathlib import Path\n",
        "import random"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:32:24.454516Z",
          "start_time": "2023-12-22T21:32:18.561210Z"
        },
        "id": "d6721b88f77e8d40"
      },
      "id": "d6721b88f77e8d40"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zugriff auf ein AI-Modell\n",
        "\n",
        "Wir nutzen ein bereits trainiertes Modell von OpenAI, um unsere Applikation zu erstellen. Dieses Modell wurde mit einer großen Menge von Textdaten trainiert und kann daher auf viele verschiedene Fragen antworten. Wir können das Modell verwenden, um eine Frage zu stellen und eine Antwort zu erhalten.\n",
        "\n",
        "Um Zugriff auf das Modell zu erhalten, müssen wir einen Zugriffscode (`key`) eingeben. Nachfolgender Code fragt uns nach diesem `key`, so dass wir ihn verwenden können, um Zugriff auf das Modell zu bekommen.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2d4d6e9f816c66bc"
      },
      "id": "2d4d6e9f816c66bc"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bitte gib den Zugriffscode ein:\n",
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "print(\"Bitte gib den Zugriffscode ein:\")\n",
        "key = getpass.getpass()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:32.762292Z",
          "start_time": "2023-12-22T21:34:30.627365Z"
        },
        "id": "f77f8deb5d35765c",
        "outputId": "abc48012-622a-4c59-f5a7-6972632c0a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f77f8deb5d35765c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ziel\n",
        "\n",
        "In diesem Workshop versuchen wir einen Chatbot zu erstellen, welchen wir Fragen über unsere Dokumente stellen können. Beispielsweise können wir Schulmaterial hochladen und der Chatbot sollte dann in der Lage sein, Fragen über dieses Material zu beantworten. Später können wir den Chatbot auch nutzen um Fragen zu den Dokumenten zu generieren, so dass wir uns auf eine Prüfung besser vorebereiten können."
      ],
      "metadata": {
        "collapsed": false,
        "id": "225298b5faafc9b5"
      },
      "id": "225298b5faafc9b5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fragen zu einem Dokument stellen\n",
        "\n",
        "Wir beginnen sehr simpel und Fragen den Chatbot über unsere Dokumente aus. Nachfolgender Code fragt ein AI Modell was unsere Dokumente beinhalten. Wir können den Code ausführen und sehen, was passiert.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1b29aea98535b81e"
      },
      "id": "1b29aea98535b81e"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Das kann ich nicht wissen, da ich keine Informationen über Ihre Dokumente habe. Sie können jedoch selbst überprüfen, welche Dokumente Sie besitzen und was sie enthalten. Falls Sie konkrete Fragen zu bestimmten Dokumenten haben, können Sie mir gerne mehr Details geben, damit ich Ihnen weiterhelfen kann.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Zuerst erstellen wir eine Verbindung zum Sprachmodell\n",
        "llm = ChatOpenAI(openai_api_key=key, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Dann sagen wir dem Modell, dass wir ein Mensch (Human) sind und was unsere Frage ist (content)\n",
        "frage = HumanMessage(content=\"Was beinhalten meine Dokumente?\")\n",
        "\n",
        "# Danach können wir das Modell aufrufen\n",
        "llm.invoke([frage])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:39.224139Z",
          "start_time": "2023-12-22T21:34:34.639878Z"
        },
        "id": "d9d24181bda7b23a",
        "outputId": "99e2bb50-c9ec-4a91-8b8d-dc25a47fbb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d9d24181bda7b23a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wie wir sehen kann der Chatbot unsere Frage nicht beantworten. Das liegt daran, dass er unsere Dokumente nicht kennt!"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e01be043877cc278"
      },
      "id": "e01be043877cc278"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dokument erstellen\n",
        "\n",
        "Damit es funktioniert, erstellen wir ein sehr einfaches Dokument und geben es zusammen mit der Frage in den Chatbot. Wir können den Code ausführen und sehen, was passiert.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d6d88007b76b348d"
      },
      "id": "d6d88007b76b348d"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Frage ist: \n",
            "Was beinhalten meine Dokumente? Mein Dokument hat folgenden Inhalt: Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet. Es ist eine spezielle Methode der Informationsverarbeitung.\n",
            "\n",
            "\n",
            "Die Antwort ist: \n",
            "Ihre Dokumente enthalten Informationen über Deep Learning, eine Methode des maschinellen Lernens, die künstliche neuronale Netze mit vielen Zwischenschichten zwischen Eingabe- und Ausgabeschicht verwendet. Diese Methode ermöglicht eine umfangreiche innere Struktur und ist eine spezielle Methode der Informationsverarbeitung.\n"
          ]
        }
      ],
      "source": [
        "mein_dokument = \"Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet. Es ist eine spezielle Methode der Informationsverarbeitung.\"\n",
        "\n",
        "frage = HumanMessage(content=f\"Was beinhalten meine Dokumente? Mein Dokument hat folgenden Inhalt: {mein_dokument}\")\n",
        "antwort = llm.invoke([frage])\n",
        "\n",
        "print(\"Die Frage ist: \\n\" + frage.content)\n",
        "print(\"\\n\")\n",
        "print(\"Die Antwort ist: \\n\" + antwort.content)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:44.207964Z",
          "start_time": "2023-12-22T21:34:41.393776Z"
        },
        "id": "bbf50fec2d9bc734",
        "outputId": "d1cb0637-934f-4838-c1a0-3acb49818aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bbf50fec2d9bc734"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wie wir sehen kann der Chatbot unsere Frage beantworten. Das liegt daran, dass er unser Dokument nun kennt!"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ca6b6db02581133b"
      },
      "id": "ca6b6db02581133b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Frage generieren\n",
        "\n",
        "Wir können den Chatbot auch nutzen um Fragen zu unseren Dokumenten zu generieren. Dazu gehen wir identisch vor, aber anstatt einer Zusammenfassung über den Inhalt verlangen wir eine Frage.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e81ca12cbcf14101"
      },
      "id": "e81ca12cbcf14101"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unser Input ist: \n",
            "Erstelle eine spannende Frage über den Inhalt meines Dokuments. Mein Dokument hat folgenden Inhalt: Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet. Es ist eine spezielle Methode der Informationsverarbeitung.\n",
            "\n",
            "\n",
            "Die von der AI generierte Frage ist: \n",
            "Wie können künstliche neuronale Netze durch Deep Learning mit zahlreichen Zwischenschichten eine umfangreiche innere Struktur herausbilden und welche Vorteile bringt dies für die Informationsverarbeitung?\n"
          ]
        }
      ],
      "source": [
        "frage = HumanMessage(content=f\"Erstelle eine spannende Frage über den Inhalt meines Dokuments. Mein Dokument hat folgenden Inhalt: {mein_dokument}\")\n",
        "antwort = llm.invoke([frage])\n",
        "\n",
        "print(\"Unser Input ist: \\n\" + frage.content)\n",
        "print(\"\\n\")\n",
        "print(\"Die von der AI generierte Frage ist: \\n\" + antwort.content)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:45.319404Z",
          "start_time": "2023-12-22T21:34:44.158951Z"
        },
        "id": "bf79d73438f4e670",
        "outputId": "c541e164-f915-4d6d-ff98-97a193b1f38d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bf79d73438f4e670"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nutzung von Templates\n",
        "\n",
        "Bisher haben wir Fragen mit folgendem Code gestellt:\n",
        "\n",
        "```python\n",
        "HumanMessage(content=f\"Was beinhalten meine Dokumente? Mein Dokument hat folgenden Inhalt: {mein_dokument}\")\n",
        "```\n",
        "\n",
        "Diesen Code jedes mal zu schreiben ist aber ziemlich aufwendig, besonders wenn wir später mehrere Dokumente haben. Wir können den Code vereinfachen, indem wir ein Template verwenden. Ein Template ist eine Vorlage, welche wir mit Werten füllen können. Nachfolgender Code erstellt ein Template und füllt es mit Werten.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "503c894608c3154f"
      },
      "id": "503c894608c3154f"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Der Prompt hat folgenden Inhalt:\n",
            "Was beinhalten meine Dokumente? Die Dokumente haben folgenden Inhalt: Mein Dokument Inhalt\n"
          ]
        }
      ],
      "source": [
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Was beinhalten meine Dokumente? Die Dokumente haben folgenden Inhalt: {dokument}\"\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"dokument\": \"Mein Dokument Inhalt\"})\n",
        "\n",
        "print(\"Der Prompt hat folgenden Inhalt:\\n\" + prompt.text)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:45.320347Z",
          "start_time": "2023-12-22T21:34:45.275377Z"
        },
        "id": "a63cbdc2f90aa456",
        "outputId": "7cdca4d0-259f-43b8-8fa0-8dcd8b4049c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "a63cbdc2f90aa456"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anstatt den ganzen Text zu schreiben, können wir nun einfach das Template verwenden:\n",
        "\n",
        "```python\n",
        "prompt = prompt_template.invoke({\"dokument\": \"Mein Dokument Inhalt\"})\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d99780ab7a38e40b"
      },
      "id": "d99780ab7a38e40b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline erstellen\n",
        "\n",
        "Damit wir künftig noch weniger Arbeit haben, können wir eine Pipeline erstellen. Eine Pipeline ist eine Abfolge von Operationen, welche wir nacheinander ausführen.\n",
        "\n",
        "Der Code wird nun schon etwas komplizierter. Wir erstellen eine Pipeline, welche die folgenden Schritte ausführt:\n",
        "\n",
        "1. Wir generieren den Prompt mit unserem Template\n",
        "2. Wir geben den Prompt an das AI Modell\n",
        "3. Wir geben die Antwort des AI Modells an einen Parser, welcher die Antwort in einen lesbaren Text umwandelt"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9fa7a4e78def4b4f"
      },
      "id": "9fa7a4e78def4b4f"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "source": [
        "pipeline = prompt_template | llm | StrOutputParser()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:45.321374Z",
          "start_time": "2023-12-22T21:34:45.290233Z"
        },
        "id": "e1d4cdbf9f0b89d6"
      },
      "id": "e1d4cdbf9f0b89d6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nun können wir die Pipeline verwenden, um eine Zusammenfassung über unsere Dokumente zu erhalten.\n",
        "Dazu reicht eine Zeile Code:\n",
        "\n",
        "```python\n",
        "pipeline.invoke({\"dokument\": mein_dokument})\n",
        "```"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cfa099c62bdfd198"
      },
      "id": "cfa099c62bdfd198"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Die Dokumente enthalten Informationen über Deep Learning, eine Methode des maschinellen Lernens, die künstliche neuronale Netze mit mehreren Zwischenschichten verwendet. Es wird erklärt, wie Deep Learning eine umfangreiche innere Struktur herausbildet und als spezielle Methode der Informationsverarbeitung dient.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pipeline.invoke({\"dokument\": mein_dokument})"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:48.395250Z",
          "start_time": "2023-12-22T21:34:45.298570Z"
        },
        "id": "38e7f443c9d25e5f",
        "outputId": "b091677d-9fd3-4fc0-82ab-4023aeafe611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "38e7f443c9d25e5f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verwendung von Dokumenten\n",
        "\n",
        "Bisher haben wir nur ein Dokument verwendet, welches wir direkt im Code programmiert hatten.\n",
        "\n",
        "```python\n",
        "mein_dokument = \"Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet. Es ist eine spezielle Methode der Informationsverarbeitung.\"\n",
        "```\n",
        "\n",
        "Das ist ziemlich unpraktisch, da wir so nicht mit mehreren Dokumenten arbeiten können. Zudem müssen wir jedes mal den Code ändern, wenn wir ein Dokument hinzufügen oder löschen wollen.\n",
        "\n",
        "Wir können den Code vereinfachen, indem wir alle Dokumente aus einem Ordner laden. So können wir künftig alle gewünschten Dokumente in diesen Ordner kopieren und der Chatbot wird sie automatisch verwenden.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c386414793ec22e4"
      },
      "id": "c386414793ec22e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Dokumente herunterladen\n",
        "\n",
        "Zur Demonstration laden wir Webseiten aus dem Internet als Daten herunter. Theoretisch könnten wir auch PDFs oder Word-Dateien verwenden - für den Computer sind alles Files die Text enthalten der unterschiedlich formatiert ist."
      ],
      "metadata": {
        "id": "4CZ9wCGYsmzy"
      },
      "id": "4CZ9wCGYsmzy"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://de.wikipedia.org/wiki/Maschinelles_Lernen\n",
        "!wget https://de.wikipedia.org/wiki/Deep_Learning"
      ],
      "metadata": {
        "id": "I0blRJWKs0bR",
        "outputId": "91fae3da-077f-4399-e58a-6d15e70ad9d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I0blRJWKs0bR",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-14 13:49:23--  https://de.wikipedia.org/wiki/Maschinelles_Lernen\n",
            "Resolving de.wikipedia.org (de.wikipedia.org)... 208.80.154.224, 2620:0:861:ed1a::1\n",
            "Connecting to de.wikipedia.org (de.wikipedia.org)|208.80.154.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140507 (137K) [text/html]\n",
            "Saving to: ‘Maschinelles_Lernen.1’\n",
            "\n",
            "\rMaschinelles_Lernen   0%[                    ]       0  --.-KB/s               \rMaschinelles_Lernen 100%[===================>] 137.21K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-03-14 13:49:23 (31.9 MB/s) - ‘Maschinelles_Lernen.1’ saved [140507/140507]\n",
            "\n",
            "--2024-03-14 13:49:23--  https://de.wikipedia.org/wiki/Deep_Learning\n",
            "Resolving de.wikipedia.org (de.wikipedia.org)... 208.80.154.224, 2620:0:861:ed1a::1\n",
            "Connecting to de.wikipedia.org (de.wikipedia.org)|208.80.154.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117035 (114K) [text/html]\n",
            "Saving to: ‘Deep_Learning.1’\n",
            "\n",
            "Deep_Learning.1     100%[===================>] 114.29K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-03-14 13:49:23 (26.4 MB/s) - ‘Deep_Learning.1’ saved [117035/117035]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dokumente öffnen\n",
        "\n",
        "Wir finden nun also die HTML-Dokumente in dem Ordner. Nun müssen wir noch den Inhalt der Dokumente laden. Das können wir mit dem Paket `BSHTMLLoader` machen. Nachfolgender Code lädt den Inhalt dieser Dokumente."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ad58de791860d353"
      },
      "id": "ad58de791860d353"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Datei Deep_Learning beinhaltet \n",
            "\n",
            " ''Deep Learning – Wikipedia\n",
            "Deep Learning\n",
            "aus Wikipedia, der freien Enzyklopädie\n",
            "Zur Navigation springen\n",
            "Zur Suche springen\n",
            "Geschichtete Repräsentation von Bildern auf mehreren Abstraktionsebenen[1]\n",
            "Dee''  \n",
            "\n",
            " .... \n",
            "\n",
            "\n",
            "Die Datei Maschinelles_Lernen beinhaltet \n",
            "\n",
            " ''Maschinelles Lernen – Wikipedia\n",
            "Maschinelles Lernen\n",
            "aus Wikipedia, der freien Enzyklopädie\n",
            "Zur Navigation springen\n",
            "Zur Suche springen\n",
            "Maschinelles Lernen (ML) ist ein Fachgebiet, das statistische Algo''  \n",
            "\n",
            " .... \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "html_dokumente = ['Deep_Learning', 'Maschinelles_Lernen']\n",
        "\n",
        "for html_dokument in html_dokumente:\n",
        "    loader = BSHTMLLoader(html_dokument)\n",
        "    data = loader.load()[0]\n",
        "    data.page_content = re.sub(r'\\n+', '\\n', data.page_content).strip()\n",
        "    print(f\"Die Datei {html_dokument} beinhaltet \\n\\n ''{data.page_content[:200]}''  \\n\\n .... \\n\\n\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:51.088150Z",
          "start_time": "2023-12-22T21:34:48.386699Z"
        },
        "id": "af43948a39d5070",
        "outputId": "246fd00f-d308-4eb6-d6d7-c8a71f299ff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "af43948a39d5070"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dokumente in Liste speichern\n",
        "\n",
        "Wir haben nun also den Inhalt der Dokumente geladen. Nun müssen wir die Dokumente noch speichern, beispielsweise in einer Liste `dokumente`:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "958ca0ebef37216"
      },
      "id": "958ca0ebef37216"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wir haben insgesamt 2 Dokumente.\n"
          ]
        }
      ],
      "source": [
        "dokumente = []\n",
        "\n",
        "for html_dokument in html_dokumente:\n",
        "    loader = BSHTMLLoader(html_dokument)\n",
        "    data = loader.load()[0]\n",
        "    data.page_content = re.sub(r'\\n+', '\\n', data.page_content).strip()\n",
        "    dokumente.append(data)\n",
        "\n",
        "print(f\"Wir haben insgesamt {len(dokumente)} Dokumente.\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:52.645233Z",
          "start_time": "2023-12-22T21:34:51.077534Z"
        },
        "id": "67862c6cbd865afb",
        "outputId": "6134d259-008b-4532-ee0d-7fae37a68f51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "67862c6cbd865afb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dokumente ausgeben\n",
        "\n",
        "Nun können wir die Abschnitte anschauen indem wir auf die Liste zugreifen:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "829e0ab46bd229b6"
      },
      "id": "829e0ab46bd229b6"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokument 1: Deep Learning – Wikipedia\n",
            "Deep Learning\n",
            "aus Wikipedia, der freien Enzyklopädie\n",
            "Zur Navigation springen\n",
            "Zur Suche springen\n",
            "Geschichtete Repräsentation von Bildern auf mehreren Abstraktionsebenen[1]\n",
            "Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen[2] oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet.[3][4][5] Es ist eine spezielle Methode der Informationsverarbeitung.\n",
            "Links: Eingangsschicht (input layer) mit in diesem Fall drei Eingangsneuronen. Rechts: Ausgabeschicht mit den Ausgangsneuronen, in diesem Bild zwei. Die mittlere Schicht wird als verborgen bezeichnet (hidden layer), da ihre Neuronen weder Eingänge noch Ausgänge sind. Hier ist nur eine verborgene Schicht zu sehen, aber viele Netzwerke haben deutlich mehr. Die notwendige Anzahl von Ebenen, ab denen man von „Deep Learning“ spricht, ist nicht genau festgelegt.\n",
            "Inhaltsverzeichnis\n",
            "1 Voraussetzungen und Grundlagen\n",
            "2 Geschichte, Entwicklung und Verwendung\n",
            "3 Komplexität und Grenzen der Erklärbarkeit\n",
            "4 Programmbibliotheken\n",
            "5 Literatur\n",
            "6 Weblinks\n",
            "7 Einzelnachweise\n",
            "Voraussetzungen und Grundlagen[Bearbeiten | Quelltext bearbeiten]\n",
            "Die in der Anfangszeit der künstlichen Intelligenz gelösten Probleme waren für den Menschen intellektuell schwierig, aber für Computer einfach zu verarbeiten. Diese Probleme ließen sich durch formale mathematische Regeln beschreiben. Die wahre Herausforderung an die künstliche Intelligenz bestand jedoch in der Lösung von Aufgaben, die für die Menschen leicht durchzuführen sind, deren Lösung sich aber nur schwer durch mathematische Regeln formulieren lassen. Dies sind Aufgaben, die der Mensch intuitiv löst, wie zum Beispiel Sprach- oder Gesichtserkennung.[3][6]\n",
            "Eine computerbasierte Lösung für diese Art von Aufgaben beinhaltet die Fähigkeit von Computern, aus der Erfahrung zu lernen und die Welt in Bezug auf eine Hierarchie von Konzepten zu verstehen. Hierbei ist jedes Konzept durch seine Beziehung zu einfacheren Konzepten definiert. Durch das Sammeln von Wissen aus der Erfahrung vermeidet dieser Ansatz die Notwendigkeit für die menschlichen Bediener, all das Wissen, das der Computer für seine Arbeit benötigt, formal spezifizieren zu müssen. Die Hierarchie der Konzepte erlaubt es dem Computer, komplizierte Konzepte zu erlernen, indem er sie aus einfacheren zusammensetzt. Wenn man ein Diagramm zeichnet, das zeigt, wie diese Konzepte übereinander aufgebaut werden, dann ist das Diagramm tief, mit vielen Schichten. Aus diesem Grund wird dieser Ansatz in der künstlichen Intelligenz „Deep Learning“ genannt.[3][7]\n",
            "Es ist schwierig für einen Computer, die Bedeutung von rohen sensorischen Eingangsdaten zu verstehen, wie beispielsweise in der Handschrifterkennung, wo ein Text zunächst nur als eine Sammlung von Bildpunkten existiert. Die Überführung einer Menge von Bildpunkten in eine Kette von Ziffern und Buchstaben ist sehr kompliziert. Komplexe Muster müssen aus Rohdaten extrahiert werden. Das Lernen oder Auswerten dieser Zuordnung scheint unüberwindbar schwierig, wenn sie manuell programmiert würde.[3]\n",
            "Eine der häufigsten Techniken in der künstlichen Intelligenz ist maschinelles Lernen. Maschinelles Lernen ist ein selbstadaptiver Algorithmus. Deep Learning, eine Teilmenge des maschinellen Lernens, nutzt eine Reihe hierarchischer Schichten bzw. eine Hierarchie von Konzepten, um den Prozess des maschinellen Lernens durchzuführen. Die hierbei benutzten künstlichen neuronalen Netze sind wie das menschliche Gehirn gebaut, wobei die Neuronen wie ein Netz miteinander verbunden sind. Die erste Schicht des neuronalen Netzes, die sichtbare Eingangsschicht, verarbeitet eine Rohdateneingabe, wie beispielsweise die einzelnen Pixel eines Bildes. Die Dateneingabe enthält Variablen, die der Beobachtung zugänglich sind, daher „sichtbare Schicht“.[3]\n",
            "Diese erste Schicht leitet ihre Ausgaben an die nächste Schicht weiter.\n",
            "Diese zweite Schicht verarbeitet die Informationen der vorherigen Schicht und gibt das Ergebnis ebenfalls weiter. Die nächste Schicht nimmt die Informationen der zweiten Schicht entgegen und verarbeitet sie weiter. Diese Schichten werden als versteckte Ebenen (englisch hidden layers) bezeichnet. Die in ihnen enthaltenen Merkmale werden zunehmend abstrakt. Ihre Werte sind nicht in den Ursprungsdaten angegeben. Stattdessen muss das Modell bestimmen, welche Konzepte für die Erklärung der Beziehungen in den beobachteten Daten nützlich sind. Dies geht über alle Ebenen des künstlichen neuronalen Netzes so weiter. Das Ergebnis wird in der sichtbaren letzten Schicht ausgegeben. Hierdurch wird die gewünschte komplizierte Datenverarbeitung in eine Reihe von verschachtelten einfachen Zuordnungen unterteilt, die jeweils durch eine andere Schicht des Modells beschrieben werden.[3][4][7][8]\n",
            "Geschichte, Entwicklung und Verwendung[Bearbeiten | Quelltext bearbeiten]\n",
            "Die Group method of data handling-KNNs (GMDH-ANN) der 1960er-Jahre von Oleksij Iwachnenko waren die ersten Deep-Learning-Systeme des Feedforward-Multilayer-Perzeptron-Typs.[9][10][11]\n",
            "Karl Steinbuchs Lernmatrix[12] war eines der ersten künstlichen neuronalen Netze, das aus mehreren Schichten von Lerneinheiten oder lernenden „Neuronen“ bestand. Damit war er einer der Wegbereiter des Deep Learning, bei dem es um tiefe neuronale Netze geht, die viele Aufgaben erlernen können, bei denen früheren einschichtige Perzeptronen scheitern.\n",
            "Weitere Deep-Learning-Ansätze, vor allem aus dem Bereich des maschinellen Sehens, begannen mit dem Neocognitron, einer Convolutional Neural Network (CNN) Architektur, die von Kunihiko Fukushima 1980 entwickelt wurde.[13] Alex Waibels CNN namens\n",
            "TDNN (1987) wurde durch backpropagation trainiert und erzielte Bewegungsinvarianz.[14] Im Jahr 1989 verwendeten Yann LeCun und Kollegen den Backpropagation-Algorithmus für das Training mehrschichtiger KNNs (siehe Multi-Layer-Perzeptron), mit dem Ziel, handgeschriebene Postleitzahlen zu erkennen.[15] Sven Behnke hat seit 1997 in der Neuronalen Abstraktionspyramide[16] den vorwärtsgerichteten hierarchisch-konvolutionalen Ansatz durch seitliche und rückwärtsgerichtete Verbindungen erweitert, um so flexibel Kontext in Entscheidungen einzubeziehen und iterativ lokale Mehrdeutigkeiten aufzulösen.\n",
            "Der Begriff „Deep Learning“ wurde im Kontext des maschinellen Lernens erstmals 1986 von Rina Dechter verwendet, wobei sie hiermit ein Verfahren bezeichnet, bei dem alle verwendeten Lösungen eines betrachteten Suchraums aufgezeichnet werden, die zu keiner gewünschten Lösung geführt haben. Die Analyse dieser aufgezeichneten Lösungen soll es ermöglichen, anschließende Versuche besser zu steuern und somit mögliche Sackgassen in der Lösungsfindung frühzeitig zu verhindern.[17] Heute wird der Begriff jedoch vorwiegend im Zusammenhang mit künstlichen neuronalen Netzen verwendet und tauchte in diesem Kontext erstmals im Jahr 2000 auf, in der Veröffentlichung Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications von Igor Aizenberg und Kollegen.[18][19][20]\n",
            "Zwischen 2009 und 2012 gewannen die rekurrenten bzw. tiefen vorwärtsgerichteten neuronalen Netze der Forschungsgruppe von Jürgen Schmidhuber am Schweizer KI Labor IDSIA eine Serie von acht internationalen Wettbewerben in den Bereichen Mustererkennung und maschinelles Lernen.[21] Insbesondere gewannen ihre rekurrenten LSTM-Netze[22][23] drei Wettbewerbe zur verbundenen Handschrifterkennung bei der 2009 Intl. Conf. on Document Analysis and Recognition (ICDAR) ohne eingebautes A-priori-Wissen über die drei verschiedenen zu lernenden Sprachen. Die LSTM-Netze erlernten gleichzeitige Segmentierung und Erkennung. Dies waren die ersten internationalen Wettbewerbe, die durch Deep Learning[24] oder durch rekurrente Netze gewonnen wurden.\n",
            "Die jüngsten Erfolge von Deep Learning Methoden, wie der Go-Turniergewinn des Programmes AlphaGo gegen die weltbesten menschlichen Spieler, gründen sich neben der gestiegenen Verarbeitungsgeschwindigkeit der Hardware auf den Einsatz von Deep Learning zum Training des in AlphaGo verwendeten neuronalen Netzes.[25] Gleiches gilt für die seit 2020 gelungene Vorhersage von Protein-Faltungen.[26] Diese Netze nutzen künstlich erzeugte Neuronen (Perzeptron), um Muster zu erkennen.\n",
            "Für Beiträge zu neuronalen Netzwerken und Deep Learning erhielten Yann LeCun, Yoshua Bengio und Geoffrey Hinton 2018 den Turing Award.[27]\n",
            "Komplexität und Grenzen der Erklärbarkeit[Bearbeiten | Quelltext bearbeiten]\n",
            "Tiefe neuronale Netze können eine Komplexität von bis zu hundert Millionen einzelnen Parametern und zehn Milliarden Rechenoperationen pro Eingangsdatum aufweisen. Die Interpretierbarkeit der Parameter und Erklärbarkeit des Zustandekommens der Ergebnisse ist hier nur noch eingeschränkt möglich und erfordert den Einsatz spezieller Techniken, die unter Explainable Artificial Intelligence zusammengefasst werden. Ein weiterer Ansatz ist die Verwendung von Methoden aus der Physik von Vielteilchensysteme (Statistische Physik).[28] Eine weitere Begleiterscheinung des Deep Learning ist die Anfälligkeit für Falschberechnungen, die durch subtile, bei zum Beispiel Bildern für Menschen nicht sichtbare, Manipulationen der Eingabesignale ausgelöst werden können. Dieses Phänomen wird unter Adversarial Examples zusammengefasst.[29]\n",
            "Es gibt zwei Konzepte zu Grenzen und Erklärbarkeit: „Opake KI“ und „transparente KI“. Ersteres, Opake KI, beinhaltet neuronale Netze, Deep Learning, genetische Algorithmen etc. Bei beiden Konzepten ist gemeinsam, dass die Logik dahinter inkl. der Vorhersagen und Entscheidungen nicht einfach ausgedrückt werden kann. Transparente KI kann hingegen die Entscheidungen erklären und für den Menschen verständlich machen. Die Entscheidung für oder gegen eines der beiden Konzepte endet schnell in ethischen und moralischen Vorstellungen. Ohne einen T-Switch (für vertrauensvoll oder transparent) ist Opake KI kaum zu kontrollieren. Je mehr Daten in einem Opaque-System verwendet werden (Big Data), umso eher wird die künstliche Intelligenz ein Wertesystem für sich selbst entwickeln, welche die Menschen nicht mehr verstehen können. Ein T-Switch ermöglicht es, bewusste Entscheidungen durch die Opake KI zu erlauben und an welcher Stelle man auf Transparenz bestehen sollte.\n",
            "Alles in allem betrachtet hat Opake KI einen Nachteil: Im Jahr 2016 hat Microsoft ein Experiment durchgeführt. In weniger als in 24 Stunden wurden sehr negative Ergebnisse bei der Veröffentlichung von einem Twitter Chatbot namens Tay erzielt.\n",
            "Transparente KI hingegen unterstützt eine exakte Erklärung. So kann immer die Entscheidung nachvollzogen werden.\n",
            "Programmbibliotheken[Bearbeiten | Quelltext bearbeiten]\n",
            "Neben der meist in Schulungsbeispielen zum Verständnis der internen Struktur vorgestellten Möglichkeit, ein neuronales Netz komplett eigenhändig zu programmieren, gibt es eine Reihe von Softwarebibliotheken,[30] häufig Open Source, lauffähig auf meist mehreren Betriebssystemplattformen, die in gängigen Programmiersprachen wie zum Beispiel C, C++, Java oder Python geschrieben sind. Einige dieser Programmbibliotheken unterstützen GPUs oder TPUs zur Rechenbeschleunigung oder stellen Tutorials zur Benutzung dieser Bibliotheken bereit. Mit ONNX können Modelle zwischen einigen dieser Tools ausgetauscht werden.\n",
            "TensorFlow (Python, JavaScript, C++, Java, Go, Swift) von Google\n",
            "Keras (Python, ab Version 1.4.0 auch in der TensorFlow-API enthalten)[31] – populäres Framework (2018) neben Tensorflow.[32]\n",
            "Caffe vom Berkeley Vision and Learning Center (BVLC)\n",
            "PyTorch (Python), entwickelt vom Facebook-Forschungsteam für künstliche Intelligenz\n",
            "Torch (C, Lua)[33] (Community) und das darauf aufbauende Facebook-Framework Torchnet[34]\n",
            "Microsoft Cognitive Toolkit (C++)[35]\n",
            "PaddlePaddle (Python) vom Suchmaschinenhersteller Baidu[36][37]\n",
            "OpenNN (C++), implementiert ein künstliches neuronales Netz.\n",
            "Theano (Python) von der Université de Montréal[38]\n",
            "Deeplearning4j (Java) von Skymind\n",
            "MXNet von der Apache Software Foundation[39]\n",
            "Literatur[Bearbeiten | Quelltext bearbeiten]\n",
            "François Chollet: Deep Learning mit Python und Keras: Das Praxis-Handbuch vom Entwickler der Keras-Bibliothek. mitp, 2018, ISBN 978-3-95845-838-3. \n",
            "Ian Goodfellow, Yoshua Bengio, Aaron Courville: Deep Learning: Adaptive Computation and Machine Learning. MIT Press, Cambridge USA 2016, ISBN 978-0-262-03561-3.\n",
            "Jürgen Schmidhuber: Deep learning in neural networks: An overview. In: Neural Networks, 61, 2015, S. 85, arxiv:1404.7828 [cs.NE].\n",
            "Rob F. Walker: Artifical Intelligence in Business: Balancing Risk and Reward, 2017, S. 1–23.\n",
            "Weblinks[Bearbeiten | Quelltext bearbeiten]\n",
            "Commons: Deep learning – Sammlung von Bildern, Videos und Audiodateien\n",
            "Luis Serrano: A friendly introduction to Deep Learning and Neural Networks auf YouTube, 26. Dezember 2016, abgerufen am 7. November 2018.\n",
            "Deep Learning – Einführung. Übersichtsartikel zum Thema Deep Learning\n",
            "Thema: Deep Learning. heise online\n",
            "Deep Learning: Wie Maschinen lernen. spektrum.de – Übersetzung des Artikels The learning machines. In: Nature, 505, S. 146–148, 2014\n",
            "Einzelnachweise[Bearbeiten | Quelltext bearbeiten]\n",
            "↑ Hannes Schulz, Sven Behnke: Deep Learning: Layer-Wise Learning of Feature Hierarchies. In: KI - Künstliche Intelligenz. Band 26, Nr. 4, November 2012, ISSN 0933-1875, S. 357–363, doi:10.1007/s13218-012-0198-z. \n",
            "↑ Herbert Bruderer: Erfindung des Computers, Elektronenrechner, Entwicklungen in Deutschland, England und der Schweiz. In: Meilensteine der Rechentechnik. 2., völlig neu bearbeitete und stark erweiterte Auflage. Band 2. De Gruyter, 2018, ISBN 978-3-11-060261-6, Wörterverzeichnis zur Technikgeschichte, S. 408 (eingeschränkte Vorschau in der Google-Buchsuche [abgerufen am 23. November 2019]). \n",
            "↑ a b c d e f \n",
            "Ian Goodfellow, Yoshua Bengio, Aaron Courville: Deep Learning. MIT Press, abgerufen am 19. Februar 2017 (englisch). \n",
            "↑ a b \n",
            "David Kriesel: Ein kleiner Überblick über Neuronale Netze. (PDF; 6,1 MB) In: dkriesel.com. 2005, abgerufen am 21. Januar 2019. \n",
            "↑ Li Deng, Dong Yu: Deep Learning: Methods and Applications. 1. Mai 2014 (microsoft.com [abgerufen am 17. Mai 2020]). \n",
            "↑ Mathias Schuh, Lukas Friehoff: Deep Learning im Rechtsmarkt. In: LEGAL REVOLUTIONary. 23. Mai 2019, abgerufen am 23. August 2021.\n",
            "↑ a b \n",
            "Michael Nielsen: Neural Networks and Deep Learning. Determination Press, abgerufen am 21. Februar 2017 (englisch). \n",
            "↑ \n",
            "Li Deng, Dong Yu: Deep Learning: Methods and Applications. In: Microsoft Research (Hrsg.): Foundations and Trends in Signal Processing. Vol. 7, Nr. 3-4, 1. Mai 2014, ISSN 1932-8346 (englisch, microsoft.com [abgerufen am 22. Februar 2017]). \n",
            "↑ Ivakhnenko, A. G. and Lapa, V. G. (1965). Cybernetic Predicting Devices. CCM Information Corpo-ration.\n",
            "↑ Jürgen Schmidhuber: Deep learning in neural networks: An overview. In: Neural Networks. 61, 2015, S. 85, arxiv:1404.7828 [cs.NE].\n",
            "↑ Jürgen Schmidhuber: Critique of Paper by “Deep Learning Conspiracy” (Nature 521 p 436). In: people.idsia.ch. Juni 2015, abgerufen am 12. April 2019.\n",
            "↑ Karl Steinbuch: Die Lernmatrix. In: Kybernetik. 1. Jahrgang, Nr. 1, 1961, S. 36–45. \n",
            "↑ Kunihiko Fukushima: Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position. In: Biological Cybernetics. 36. Jahrgang, Nr. 4, 1980, S. 193–202, doi:10.1007/BF00344251 (englisch, princeton.edu [PDF]). \n",
            "↑ Alex Waibel: Phoneme Recognition Using Time-Delay Neural Networks. Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE), Tokyo, Japan, 1987. 1987 (englisch). \n",
            "↑ Yann LeCun et al.: Backpropagation Applied to Handwritten Zip Code Recognition. Neural Computation, 1, 1989, S. 541–551, abgerufen am 11. Mai 2020.\n",
            "↑ Sven Behnke: Hierarchical Neural Networks for Image Interpretation (= Lecture Notes in Computer Science. Band 2766). Springer Berlin Heidelberg, Berlin, Heidelberg 2003, ISBN 3-540-40722-7, doi:10.1007/b11963. \n",
            "↑ Rina Dechter: Learning while searching in constraint-satisfaction problems. (PDF; 531 kB) In: fmdb.cs.ucla.edu. University of California, Computer Science Department, Cognitive Systems Laboratory, 1985, archiviert vom Original (nicht mehr online verfügbar) am 16. September 2021; abgerufen am 9. Juli 2020 (englisch).  Info: Der Archivlink wurde automatisch eingesetzt und noch nicht geprüft. Bitte prüfe Original- und Archivlink gemäß Anleitung und entferne dann diesen Hinweis.@1@2Vorlage:Webachiv/IABot/fmdb.cs.ucla.edu \n",
            "↑ Horváth & Partners: „Künstliche Intelligenz wird alles ändern“ (ab 0:11:30) auf YouTube, 9. Mai 2016, abgerufen am 6. November 2018 (Vortrag von Jürgen Schmidhuber).\n",
            "↑ Jürgen Schmidhuber: Deep Learning since 1991. In: people.idsia.ch. 31. März 2017, abgerufen am 1. Dezember 2018. \n",
            "↑ Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle: Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science & Business Media, 2013, ISBN 978-1-4757-3115-6 (englisch, google.com). \n",
            "↑ 2012 Kurzweil AI Interview (Memento vom 31. August 2018 im Internet Archive) mit Jürgen Schmidhuber zu den acht Wettbewerben, die sein Deep Learning Team zwischen 2009 und 2012 gewann\n",
            "↑ Alex Graves, Jürgen Schmidhuber: Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks. In: Yoshua Bengio, Dale Schuurmans, John Lafferty, Chris K. I. Williams, Aron Culotta (Hrsg.): Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC. Neural Information Processing Systems (NIPS) Foundation, 2009, S. 545–552\n",
            "↑ A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber: A Novel Connectionist System for Improved Unconstrained Handwriting Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, Band 31, Nr. 5, 2009.\n",
            "↑ Y. Bengio: Learning Deep Architectures for AI. (Memento vom 21. März 2014 im Internet Archive) Now Publishers, 2009.\n",
            "↑ Demis Hassabis: AlphaGo: using machine learning to master the ancient game of Go. In: blog.google. Google, 27. Januar 2016, abgerufen am 16. Juli 2017 (englisch). \n",
            "↑ AlphaFold: a solution to a 50-year-old grand challenge in biology. In: deepmind.com. 30. November 2020, abgerufen am 19. Dezember 2020 (englisch). \n",
            "↑ Alexander Neumann: Deep Learning: Turing Award für Yoshua Bengio, Geoffrey Hinton und Yann LeCun – heise online. In: heise.de. 28. März 2019, abgerufen am 29. März 2019. \n",
            "↑ John Hertz, Anders Krogh, Richard G. Palmer: Introduction to the theory of neural computation (= Santa Fé Institute studies in the sciences of complexity Lecture notes. Nr. 1). Addison-Wesley, Reading, Mass. 1999, ISBN 0-201-51560-1. \n",
            "↑ Leilani H. Gilpin, David Bau, Ben Z. Yuan, Ayesha Bajwa, Michael Specter: Explaining Explanations: An Overview of Interpretability of Machine Learning. In: 2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA). IEEE, Turin 2018, ISBN 978-1-5386-5090-5, S. 80–89, doi:10.1109/DSAA.2018.00018 (ieee.org [abgerufen am 8. Dezember 2019]). \n",
            "↑ Dan Clark: Top 16 Open Source Deep Learning Libraries and Platforms. KDnuggets, April 2018, abgerufen am 8. Januar 2019 (englisch). \n",
            "↑ Keras Documentation. In: Keras: Deep Learning library for Theano and TensorFlow. Abgerufen am 6. März 2017 (englisch). \n",
            "↑ Why use Keras? In: keras.io. Abgerufen am 8. Januar 2020 (englisch): „Keras is also a favorite among deep learning researchers, coming in #2 in terms of mentions in scientific papers uploaded to the preprint server arXiv.org. Keras has also been adopted by researchers at large scientific organizations, in particular CERN and NASA.“ \n",
            "↑ Torch | Scientific computing for LuaJIT. Abgerufen am 17. Februar 2017 (englisch). \n",
            "↑ Rainald Menge-Sonnentag: Maschinelles Lernen: Facebook veröffentlicht Open-Source-Framework für Torch. In: heise.de. 24. Juni 2016, abgerufen am 17. Februar 2017. \n",
            "↑ The Microsoft Cognitive Toolkit. In: microsoft.com. Abgerufen am 11. August 2017 (amerikanisches Englisch). \n",
            "↑ Startseite. In: paddlepaddle.org. Abgerufen am 17. Februar 2017 (englisch). \n",
            "↑ Alexander Neumann: Baidu gibt Deep-Learning-System als Open Source frei. In: heise.de. 2. September 2016, abgerufen am 17. Februar 2017. \n",
            "↑ Theano. In: deeplearning.net. Archiviert vom Original (nicht mehr online verfügbar) am 8. November 2020; abgerufen am 20. September 2019 (englisch).  Info: Der Archivlink wurde automatisch eingesetzt und noch nicht geprüft. Bitte prüfe Original- und Archivlink gemäß Anleitung und entferne dann diesen Hinweis.@1@2Vorlage:Webachiv/IABot/deeplearning.net \n",
            "↑ Apache MXNet (Incubating) – A flexible and efficient library for deep learning. In: mxnet.apache.org. Abgerufen am 5. September 2019 (englisch). \n",
            "Abgerufen von „https://de.wikipedia.org/w/index.php?title=Deep_Learning&oldid=241897511“\n",
            "Kategorien: NeuroinformatikDeep LearningVersteckte Kategorien: Wikipedia:Defekte Weblinks/Ungeprüfte Archivlinks 2023-12Wikipedia:Defekte Weblinks/Ungeprüfte Archivlinks 2022-10\n",
            "Navigationsmenü\n",
            "Meine Werkzeuge\n",
            "Nicht angemeldetDiskussionsseiteBeiträgeBenutzerkonto erstellenAnmelden\n",
            "Namensräume\n",
            "ArtikelDiskussion\n",
            "Deutsch\n",
            "Ansichten\n",
            "LesenBearbeitenQuelltext bearbeitenVersionsgeschichte\n",
            "Weitere\n",
            "Suche\n",
            "Navigation\n",
            "HauptseiteThemenportaleZufälliger Artikel\n",
            "Mitmachen\n",
            "Artikel verbessernNeuen Artikel anlegenAutorenportalHilfeLetzte ÄnderungenKontaktSpenden\n",
            "Werkzeuge\n",
            "Links auf diese SeiteÄnderungen an verlinkten SeitenSpezialseitenPermanenter LinkSeiten­­informationenArtikel zitierenKurzlinkQR-Code herunterladenWikidata-Datenobjekt\n",
            "Drucken/​exportieren\n",
            "Buch erstellenAls PDF herunterladenDruckversion\n",
            "In anderen Projekten\n",
            "Commons\n",
            "In anderen Sprachen\n",
            "AfrikaansالعربيةAzərbaycancaБългарскиবাংলাBosanskiCatalàکوردیČeštinaDanskEnglishEspañolEestiEuskaraفارسیSuomiFrançaisGaeilgeGalegoעבריתՀայերենBahasa IndonesiaItaliano日本語한국어മലയാളംМонголBahasa MelayuNederlandsNorsk bokmålOccitanPolskiپښتوPortuguêsRuna SimiRomânăРусскийසිංහලSimple EnglishSlovenščinaShqipСрпски / srpskiSvenskaதமிழ்ไทยTürkçeУкраїнськаTiếng Việt中文Bân-lâm-gú粵語\n",
            "Links bearbeiten\n",
            " Diese Seite wurde zuletzt am 5. Februar 2024 um 16:45 Uhr bearbeitet.\n",
            "Abrufstatistik · Autoren \n",
            "Der Text ist unter der Lizenz „Creative-Commons Namensnennung – Weitergabe unter gleichen Bedingungen“ verfügbar; Informationen zu den Urhebern und zum Lizenzstatus eingebundener Mediendateien (etwa Bilder oder Videos) können im Regelfall durch Anklicken dieser abgerufen werden. Möglicherweise unterliegen die Inhalte jeweils zusätzlichen Bedingungen. Durch die Nutzung dieser Website erklären Sie sich mit den Nutzungsbedingungen und der Datenschutzrichtlinie einverstanden.\n",
            "Wikipedia® ist eine eingetragene Marke der Wikimedia Foundation Inc.\n",
            "Datenschutz\n",
            "Über Wikipedia\n",
            "Impressum\n",
            "Verhaltenskodex\n",
            "Entwickler\n",
            "Statistiken\n",
            "Stellungnahme zu Cookies\n",
            "Mobile Ansicht\n",
            "\n",
            "\n",
            "Dokument 2: Maschinelles Lernen – Wikipedia\n",
            "Maschinelles Lernen\n",
            "aus Wikipedia, der freien Enzyklopädie\n",
            "Zur Navigation springen\n",
            "Zur Suche springen\n",
            "Maschinelles Lernen (ML) ist ein Fachgebiet, das statistische Algorithmen entwickelt und untersucht. Diese Algorithmen können aus Daten, die in maschinenlesbarer Form vorliegen und Informationen über Beobachtungen oder Erfahrungen enthalten, ein bestimmtes Verhalten lernen. Das Verhalten wird nicht explizit programmiert, sondern von den Algorithmen direkt aus den Daten gelernt. Das Lernen aus Daten bezeichnet man in der mathematischen Statistik auch als Statistisches Lernen.[1]\n",
            "Aus dem weiten Spektrum möglicher Anwendungen seien hier genannt: Spamfilter, automatisierte Diagnose­verfahren, Erkennung von Kreditkartenbetrug, Aktienmarkt­analysen, Klassifikation von Nukleotidsequenzen, Sprach- und Texterkennung sowie AlphaGo.\n",
            "Allgemein formuliert ist das Ziel beim maschinellen Lernen, dass ein Algorithmus aus Daten eine Funktion lernt, die anschließend auch für nicht gelernte Dateneingaben eine korrekte Ausgabe erzeugt. Damit der Algorithmus lernen kann, was „korrekt“ ist, werden beim überwachten Lernen in den Daten, die zum Lernen verwendet werden, bereits korrekte Ausgabewerte zur Verfügung gestellt. Typische Anwendungsbeispiele sind Klassifikation und Regression. Beim bestärkenden Lernen lernen die Algorithmen die geforderten Ausgabewerte aus kontinuierlichen Rückmeldungen. Ein bekanntes Anwendungsbeispiel ist AlphaGo. Beim unüberwachten Lernen durchsuchen die Algorithmen die Daten ohne vorgegebene Ausgabewerte oder Rückmeldungen beispielsweise nach Kriterien für die Einteilung in unterschiedliche Cluster oder nach korrelierenden Merkmalen, die zusammengefasst werden können, um die Daten zu vereinfachen. Da es keine Vorgaben gibt, können die Algorithmen unterschiedliche Lösungen vorschlagen, die anschließend zu bewerten sind. Ein typisches Anwendungsbeispiel ist die Vorbereitung von Datensätzen für das überwachte Lernen.[2]\n",
            "In der Theorie des computergestützten Lernens bietet das Probably Approximately Correct Learning einen Rahmen für die Beschreibung des ML.\n",
            "Inhaltsverzeichnis\n",
            "1 Verwandte Fachgebiete\n",
            "2 Methoden\n",
            "2.1 Repräsentation des Wissens\n",
            "2.2 Trainingsüberwachung\n",
            "2.2.1 Überwachtes Lernen\n",
            "2.2.2 Unüberwachtes Lernen\n",
            "2.2.3 Bestärkendes Lernen\n",
            "2.3 Batch- und Online-Learning\n",
            "2.4 Lernen von Instanzen oder Modellen\n",
            "3 Modelle\n",
            "3.1 Lineare Regression\n",
            "3.2 k-Means-Algorithmus\n",
            "3.3 Support Vector Machines\n",
            "3.4 Entscheidungsbäume\n",
            "3.5 Random Forests\n",
            "3.6 Künstliche Neuronale Netze\n",
            "3.7 Generative Adversarial Networks\n",
            "4 Automatisiertes Maschinelles Lernen\n",
            "5 Siehe auch\n",
            "6 Literatur\n",
            "7 Weblinks\n",
            "8 Einzelnachweise\n",
            "Verwandte Fachgebiete[Bearbeiten | Quelltext bearbeiten]\n",
            "Das maschinelle Lernen ist ein Teilgebiet des Fachgebietes „Künstliche Intelligenz“, auch KI genannt. Ursprünglich gab es nur das Fachgebiet „Künstliche Intelligenz“. Etwa ab 1980 entwickelten sich die Ziele und Methoden innerhalb der KI in verschiedene Richtungen. Die meisten Forscher untersuchten vorrangig, welche Rolle Wissen bei der Entstehung von Intelligenz spielt. Parallel untersuchte eine kleine Gruppe von Forschern, ob sich die Leistung von Computern bei Vorhersagen dadurch verbessern lässt, dass sie Wissen aus Daten lernen, die Informationen zu Erfahrungen aus dem Problemfeld enthalten. Der Bereich KI zeigte zu dieser Zeit nur wenig Interesse am Lernen aus Daten. Deshalb gründeten diese Forscher den neuen Bereich ML. Das Ziel von ML ist nicht mehr, künstliche Intelligenz zu erreichen, sondern praktische Probleme zu lösen.[3]\n",
            "ML und Statistik verwenden sehr ähnliche Methoden. Die beiden Fachgebiete unterscheiden sich allerdings in ihrem Hauptziel. Viele der eingesetzten Methoden können sowohl angewendet werden, um Schlussfolgerungen zu ziehen als auch, um Vorhersagen zu treffen. Die Statistik benutzt Daten von sorgfältig ausgewählten Stichproben, um daraus Rückschlüsse zu Eigenschaften einer zu untersuchenden Gesamtmenge zu ziehen. Die Methoden in der Statistik legen deshalb den Schwerpunkt darauf, statistische Modelle zu erstellen und diese genau an die gegebene Problemstellung anzupassen. Damit kann man berechnen, mit welcher Wahrscheinlichkeit gefundene Zusammenhänge echt sind und nicht durch Störungen erklärt werden können. Die Methoden im ML hingegen verarbeiten große Datenmengen und lernen daraus mit allgemein formulierten Algorithmen Zusammenhänge, die verallgemeinert und für Vorhersagen benutzt werden. Auch wenn ML für ein gegebenes Problem überzeugende Vorhersageergebnisse liefert, kann man daraus möglicherweise keine Regeln ableiten, solange das explizite Modell fehlt.[4]\n",
            "ML ist ein wichtiger Baustein des interdisziplinären Wissenschaftsfeldes „Data Science“.[5] Dieser Bereich befasst sich mit der Extraktion von Erkenntnissen, Mustern und Schlüssen sowohl aus strukturierten als auch unstrukturierten Daten.\n",
            "ML überschneidet sich teilweise mit „Knowledge Discovery in Databases“ und „Data-Mining“, bei denen es jedoch vorwiegend um das Finden von neuen Mustern und Gesetzmäßigkeiten geht. Viele Algorithmen können für beide Zwecke verwendet werden. Methoden der „Knowledge Discovery in Databases“ können genutzt werden, um Lerndaten für ML zu produzieren oder vorzuverarbeiten. Im Gegenzug dazu finden Algorithmen aus dem ML beim Data-Mining Anwendung.[2]:16–18\n",
            "ML umfasst alle Methoden, mit denen Computer Wissen aus Daten lernen. Ein Teilgebiet von ML sind „Künstliche Neuronale Netze“. Ein Teilgebiet innerhalb der künstlichen neuronalen Netze ist wiederum „Deep Learning“. Mit Hilfe von künstlichen neuronalen Netzen und Deep Learning konnte die Leistung gegenüber früheren Ansätzen beispielsweise in den Bereichen natürliche Sprachverarbeitung und Spracherkennung deutlich gesteigert werden.[5]\n",
            "Die Mathematische Optimierung ist eine mathematische Grundlage des ML. Die bestmögliche Anpassung eines Modells an die Trainingsdaten ist ein Optimierungsproblem. Beispielsweise wenden einige Lernalgorithmen das Gradientenverfahren an, um Modellparameter zu optimieren.\n",
            "Methoden[Bearbeiten | Quelltext bearbeiten]\n",
            "Die Methoden von ML können nach verschiedenen Kriterien in Kategorien eingeteilt werden.\n",
            "Repräsentation des Wissens[Bearbeiten | Quelltext bearbeiten]\n",
            "Das maschinelle Lernen verarbeitet Daten, die Informationen enthalten, und leitet daraus mit induktiven Methoden Wissen ab. Ob das abgeleitete Wissen korrekt ist, hängt von der Anzahl und der Repräsentativität der zur Verfügung gestellten Datenpunkte ab. Viele Anwendungsfälle erfordern, dass die Regeln, die das Modell aus Daten gelernt hat und im Einsatz verwendet, von Menschen nachvollzogen und überprüft werden können.[6]\n",
            "Zu Beginn hatte ML das Ziel, automatisch Expertensysteme zu erzeugen und nachzubilden, wie Menschen lernen. Der Schwerpunkt lag auf symbolischen Ansätzen. Dabei wird das Wissen in Form von Regeln oder logischen Formeln repräsentiert. Bei symbolischen Ansätzen können Menschen die Zusammenhänge, die das System gefunden hat, leicht erkennen und überprüfen.\n",
            "Später änderte ML sein Ziel dahingehend, dass alle Methoden untersucht werden sollten, die die Leistung steigern können. Dazu gehören auch nicht-symbolische Ansätze, beispielsweise künstliche neuronale Netze, die zwar ein berechenbares Verhalten lernen, das erworbene Wissen aber implizit repräsentieren. Bei nicht-symbolischen Ansätzen können Menschen nicht erkennen, welche Zusammenhänge das System gefunden hat.[3] Somit ist eine Überprüfung sehr aufwendig.\n",
            "Bei den symbolischen Ansätzen werden aussagenlogische und prädikatenlogische Systeme unterschieden. In der Aussagenlogik hat jede Aussage einen von genau zwei Wahrheitswerten. Der Wahrheitswert jeder zusammengesetzten Aussage ist eindeutig durch die Wahrheitswerte ihrer Teilaussagen bestimmt. Ein Beispiel für ein solches System ist ein Entscheidungsbaum, Beispiele für entsprechende Algorithmen sind ID3 und sein Nachfolger C4.5. Die Prädikatenlogik ist eine Erweiterung der Aussagenlogik. Sie spielt in der Konzeption und Programmierung von Expertensystemen eine Rolle, siehe auch induktive logische Programmierung.\n",
            "Trainingsüberwachung[Bearbeiten | Quelltext bearbeiten]\n",
            "Die praktische Umsetzung geschieht mittels Algorithmen. Verschiedene Lernalgorithmen aus dem Bereich des maschinellen Lernens lassen sich grob in drei Gruppen einteilen:[7] überwachtes Lernen (englisch supervised learning), unüberwachtes Lernen (englisch unsupervised learning) und bestärkendes Lernen (engl. reinforcement learning).\n",
            "Überwachtes Lernen[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Überwachtes Lernen\n",
            "Beim überwachten Lernen wird ein Lernalgorithmus mit Datensätzen trainiert und validiert, die für jede Eingabe einen passenden Ausgabewert enthalten. Man bezeichnet solche Datensätze als markiert oder gelabelt. Die Methode richtet sich also nach einer im Vorhinein festgelegten zu lernenden Ausgabe, deren Ergebnisse bekannt sind. Die Ergebnisse des Lernprozesses können mit den bekannten, richtigen Ergebnissen verglichen, also „überwacht“, werden.\n",
            "Die Algorithmen bauen zunächst in einer Lernphase aus einem Trainingsdatensatz ein statistisches Modell auf. Das Schließen von Daten auf (hypothetische) Modelle wird als statistische Inferenz bezeichnet. Nach der Lernphase wird die Qualität des erzeugten Modells mit einem Testdatensatz überprüft, der beim Training nicht verwendet wurde. Das Ziel ist, dass das Modell auch für völlig neue Daten das geforderte Verhalten zeigt. Dazu muss sich das Modell gut an die Trainingsdaten anpassen, gleichzeitig muss eine Überanpassung vermieden werden.[8][9]\n",
            "Es lassen sich noch einige Unterkategorien für überwachtes Lernen identifizieren, die in der Literatur häufiger erwähnt werden:\n",
            "Teilüberwachtes Lernen (englisch semi-supervised learning): Der Datensatz enthält nur für einen Teil der Eingaben die dazugehörigen Ausgaben.[10] Nun werden in der Regel zwei Algorithmen kombiniert. Im ersten Schritt teilt ein Algorithmus für unüberwachtes Lernen die Eingaben in Cluster auf und labelt anschließend alle Eingaben eines Clusters mit dem Label anderer Datenpunkte aus demselben Cluster. Danach wird ein Algorithmus für überwachtes Lernen eingesetzt.[11]\n",
            "Aktives Lernen (englisch active learning): Der Algorithmus hat die Möglichkeit, für einen Teil der Eingaben die korrekten Ausgaben zu erfragen. Dabei muss der Algorithmus die Fragen bestimmen, welche einen hohen Informationsgewinn versprechen, um die Anzahl der Fragen möglichst klein zu halten.[12]\n",
            "Selbstüberwachtes Lernen (englisch self-supervised learning): Diese Methode kann wie das teilüberwachte Lernen in zwei Schritte aufgeteilt werden. Im ersten Schritt erstellt ein Algorithmus aus einem völlig ungelabelten Datensatz einen neuen Datensatz mit Pseudolabeln. Dieser Schritt gehört eigentlich zum unüberwachten Lernen. Danach wird ein Algorithmus für überwachtes Lernen eingesetzt.[11]:43-44\n",
            "Unüberwachtes Lernen[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Unüberwachtes Lernen\n",
            "Der Algorithmus erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. Clustering-Verfahren teilen Daten in mehrere Kategorien ein, die sich durch charakteristische Muster voneinander unterscheiden. Diese Verfahren erstellen selbständig Klassifikatoren. Ein wichtiger Algorithmus in diesem Zusammenhang ist der EM-Algorithmus, der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-Algorithmus findet sich beispielsweise in den Hidden Markov Models (HMMs). Andere Methoden des unüberwachten Lernens, z. B. die Hauptkomponentenanalyse, zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt.\n",
            "Bestärkendes Lernen[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Bestärkendes Lernen\n",
            "Beim bestärkenden Lernen entwickeln Agenten selbständig eine Strategie, um erhaltene Belohnungen zu maximieren.[13][14] Aufgrund seiner Allgemeingültigkeit wird dieses Gebiet auch in vielen anderen Disziplinen untersucht, z. B. in der Spieltheorie, der Kontrolltheorie, dem Operations Research, der Informationstheorie, der simulationsbasierten Optimierung, den Multiagentensystemen, der Schwarmintelligenz, der Statistik und den genetischen Algorithmen. Beim maschinellen Lernen wird die Umgebung normalerweise als Markov-Entscheidungsprozess (MDP) dargestellt. Viele Algorithmen des Verstärkungslernens verwenden Techniken der dynamischen Programmierung.[15] Verstärkungslernalgorithmen setzen keine Kenntnis eines exakten mathematischen Modells des MDP voraus und werden eingesetzt, wenn exakte Modelle nicht durchführbar sind. Verstärkungslernalgorithmen werden in autonomen Fahrzeugen oder beim Lernen eines Spiels gegen einen menschlichen Gegner eingesetzt.\n",
            "Batch- und Online-Learning[Bearbeiten | Quelltext bearbeiten]\n",
            "Beim Batch-Learning, auch Offline-Learning genannt, werden alle Eingabe/Ausgabe-Paare auf einmal eingelesen. Das System kann in dieser Zeit nicht benutzt werden und ist in der Regel Offline. Nach dem Training kann das System nicht durch neue Daten verbessert werden. Wenn neue Daten dazu gelernt werden sollen, dann ist ein vollständiger neuer Trainingslauf mit allen Daten, alten und neuen, erforderlich.\n",
            "Beim Online-Learning, auch inkrementelles Lernen genannt, wird das System inkrementell mit kleineren Datensätzen trainiert. Das Verfahren eignet sich gut für Systeme, die sich schnell an Veränderungen anpassen müssen. Dabei müssen neue Daten genau so hochwertig sein wie alte. Wenn neue Daten beispielsweise ungeprüft von einem defekten Sensor übernommen werden, besteht die Gefahr, dass das Modell mit der Zeit schlechter wird.[16][11]:46-49\n",
            "Lernen von Instanzen oder Modellen[Bearbeiten | Quelltext bearbeiten]\n",
            "Beim ML geht es oft darum, Vorhersagen zu treffen. Dazu muss ein System von den gelernten Daten auf unbekannte Daten verallgemeinern.\n",
            "Eine einfache Methode besteht darin, dass das System direkt die Merkmale von neuen Datenpunkten mit denen der gelernten Datenpunkte vergleicht und ihre Ähnlichkeit vergleicht. Man bezeichnet das als instanzbasiertes Lernen. In der Trainingsphase lernt das System nur die Trainingsdaten. Danach berechnet es bei jeder Anfrage die Ähnlichkeit von neuen Datenpunkten mit gelernten und erzeugt aus dem Ähnlichkeitsmaß eine Antwort. Ein Beispiel ist die Nächste-Nachbarn-Klassifikation.\n",
            "Die andere Methode besteht darin, dass das System in der Trainingsphase ein Modell entwickelt und seine Parameter so an die Trainingsdaten anpasst, dass das Modell korrekte Verallgemeinerungen oder Vorhersagen machen kann. Man bezeichnet das als modellbasiertes Lernen.[11]:49-50\n",
            "Modelle[Bearbeiten | Quelltext bearbeiten]\n",
            "Beim maschinellen Lernen wird oft ein Modell erstellt, das mit einem Trainingsdatensatz trainiert wird und danach weitere Daten verarbeiten kann, um Vorhersagen zu treffen. Es gibt viele Arten von Modellen, die untersucht wurden und in solchen Systemen verwendet werden.\n",
            "Lineare Regression[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Lineare Regression\n",
            "Einfache lineare Regression auf einem Datensatz\n",
            "Die lineare Regression ist ein statistisches Verfahren, mit dem versucht wird, eine beobachtete abhängige Variable durch eine oder mehrere unabhängige Variablen zu erklären. Bei der linearen Regression wird dabei ein lineares Modell angenommen. Bei der einfachen linearen Regression wird mithilfe zweier Parameter eine Gerade (Regressionsgerade) so durch eine Punktwolke gelegt, dass der lineare Zusammenhang zwischen \n",
            "X\n",
            "{\\displaystyle X}\n",
            " und \n",
            "Y\n",
            "{\\displaystyle Y}\n",
            " möglichst gut beschrieben wird.\n",
            "Um eine möglichst genaue Vorhersage für die abhängige Variable zu erhalten, wird eine sogenannte „Kostenfunktion“ aufgestellt. Diese Funktion beschreibt die mittlere quadratische Abweichung, die dadurch entsteht, dass die Regressionsgerade die zu erklärende Variable nur approximiert und nicht genau darstellt. Der Lernalgorithmus minimiert diese Kostenfunktion.\n",
            "k-Means-Algorithmus[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: k-Means-Algorithmus\n",
            "Die Objekte werden dem Cluster zugewiesen, dessen Zentrum am nächsten ist.\n",
            "Der k-Means-Algorithmus ist ein Verfahren zur Vektorquantisierung, das auch zur Clusteranalyse verwendet wird. Dabei wird aus einer Menge von ähnlichen Objekten eine vorher bekannte Anzahl von k Gruppen gebildet. Der Algorithmus ist eine der am häufigsten verwendeten Techniken zur Gruppierung von Objekten, da er schnell die Zentren der Cluster findet. Dabei bevorzugt der Algorithmus Gruppen mit geringer Varianz und ähnlicher Größe.\n",
            "In der Regel wird ein approximativer Algorithmus verwendet, der mit zufälligen Mittelwerten aus dem Trainigsdatensatz beginnt und sich danach in mehreren Schritten einer guten Clusteraufteilung annähert. Da die Problemstellung von k abhängig ist, muss dieser Parameter vom Benutzer festgelegt werden.\n",
            "Support Vector Machines[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Support Vector Machine\n",
            "Zwei mögliche Trenngeraden mit verschiedenen Randgrößen\n",
            "Eine Support Vector Machine dient als Klassifikator und Regressor. Eine Support Vector Machine unterteilt eine Menge von Objekten so in Klassen, dass um die Klassengrenzen herum ein möglichst breiter Bereich frei von Objekten bleibt; sie ist ein sogenannter Large Margin Classifier (dt. „Breiter-Rand-Klassifikator“).\n",
            "Jedes Objekt wird durch einen Vektor in einem Vektorraum repräsentiert. Aufgabe der Support Vector Machine ist es, in diesen Raum eine Hyperebene einzupassen, die als Trennfläche fungiert und die Trainingsobjekte in zwei Klassen teilt. Der Abstand derjenigen Vektoren, die der Hyperebene am nächsten liegen, wird dabei maximiert. Dieser breite, leere Rand soll später dafür sorgen, dass auch Objekte, die nicht genau den Trainingsobjekten entsprechen, möglichst zuverlässig klassifiziert werden.\n",
            "Lineare Trennbarkeit\n",
            "Eine saubere Trennung mit einer Hyperebene ist nur dann möglich ist, wenn die Objekte linear trennbar sind. Diese Bedingung ist für reale Trainingsobjektmengen im Allgemeinen nicht erfüllt. Support Vector Machines überführen beim Training den Vektorraum und damit auch die darin befindlichen Trainingsvektoren in einen höherdimensionalen Raum, um eine nichtlineare Klassengrenze einzuziehen. In einem Raum mit genügend hoher Dimensionsanzahl – im Zweifelsfall unendlich – wird auch die verschachteltste Vektormenge linear trennbar.\n",
            "Die Hochtransformation ist enorm rechenlastig und die Darstellung der Trennfläche im niedrigdimensionalen Raum im Allgemeinen unwahrscheinlich komplex und damit praktisch unbrauchbar. An dieser Stelle setzt der sogenannte Kernel-Trick an. Verwendet man zur Beschreibung der Trennfläche geeignete Kernelfunktionen, die im Hochdimensionalen die Hyperebene beschreiben und trotzdem im Niedrigdimensionalen „gutartig“ bleiben, so ist es möglich, die Hin- und Rücktransformation umzusetzen, ohne sie tatsächlich rechnerisch ausführen zu müssen.\n",
            "Entscheidungsbäume[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Entscheidungsbaum\n",
            "Dieser einfache Klassifizierungsentscheidungsbaum sagt vorher, ob ein Apfelbaum Früchte tragen wird. Knoten sind grau dargestellt, Blätter grün.\n",
            "Beim Lernen von Entscheidungsbäumen wird ein Entscheidungsbaum als Modell verwendet, um Schlussfolgerungen aus den Beobachtungen zu ziehen, die im Trainingsdatensatz enthalten sind. Gelernte Regeln werden durch Knoten und Zweige des Baums repräsentiert und Schlussfolgerungen durch seine Blätter. Ein Modell mit diskreten Ausgabewerten (in der Regel ganzen Zahlen) nennt man Klassifizierungsbaum, dabei repräsentieren die Blattknoten die Klassen und die Zweige UND-Verknüpfungen der Merkmale, die zu der Klasse führen. Ein Modell mit kontinuierlichen Ausgabewerten (in der Regel reellen Zahlen) nennt man Regressionsbaum. Der Algorithmus wählt beim Training diejenige Reihenfolge für die Abfrage der Merkmale, bei der das Modell bei jeder Verzweigung möglichst viel Information erhält. Nach dem Training kann man das Modell auch dazu verwenden, explizit und graphisch die Regeln darzustellen, die zu einer Entscheidung führen.[2]:129-149\n",
            "Der im Bild dargestellte Binärbaum benötigt als Eingabe einen Vektor mit den Merkmalen eines Apfelbaumes. Ein Apfelbaum kann beispielsweise die Merkmale alt, natürliche Sorte und reichhaltiger Boden besitzen. Beginnend mit dem Wurzelknoten werden nun die Entscheidungsregeln des Baumes auf den Eingabevektor angewendet. Gelangt man nach einer Folge ausgewerteter Regeln an ein Blatt, erhält man die Antwort auf die ursprüngliche Frage.\n",
            "Random Forests[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Random Forest\n",
            "Ein Random Forest.\n",
            "Ein Random Forest besteht aus mehreren unkorrelierten Entscheidungsbäumen. Ein Random Forest mittelt über mehrere Entscheidungsbäume, die auf verschiedenen Teilen desselben Trainingsdatensatzes trainiert wurden. Eine große Anzahl unkorrelierter Bäume macht genauere Vorhersagen möglich als ein einzelner Entscheidungsbaum. Dadurch wird in der Regel die Leistung des endgültigen Modells erheblich gesteigert.\n",
            "Künstliche Neuronale Netze[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Künstliches neuronales Netz\n",
            "Ein künstliches neuronales Netz besteht aus einer Gruppe von Knoten, die miteinander verbunden sind, Im Bild zeigt jeder Kreis ein künstliches Neuron und jeder Pfeil eine Verbindung zwischen zwei künstlichen Neuronen.\n",
            "Künstliche neuronale Netze (KNN) sind Modelle, deren Struktur von biologischen neuronalen Netzen, aus denen Tiergehirne bestehen, inspiriert wurde. Solche Modelle  können aus komplexen und scheinbar zusammenhanglosen Informationen lernen. Einige erfolgreiche Anwendungen sind Bilderkennung und Spracherkennung.\n",
            "Ein KNN wird von Einheiten oder Knoten gebildet, die miteinander verbunden sind. Die Knoten sind künstliche Neuronen. Die Verbindungen ähneln den Synapsen in einem Gehirn. Ein künstliches Neuron empfängt Signale von verbundenen Neuronen und verarbeitet sie mit einer sogenannten Aktivierungsfunktion. Zusätzlich hat jede Verbindung ein Gewicht, das den Einfluss erhöht oder reduziert, den das entsprechende Signal auf die Aktivierungsfunktion hat. Eine verbreitete Form der Aktivierungsfunktion berechnet die Summe aller gewichteten Eingangssignale und legt sie als Signal auf alle Ausgänge, wenn sie einen bestimmten Schwellenwert überschreitet. Wenn die Summe unter dem Schwellenwert liegt, erzeugt diese Form der Aktivierungsfunktion kein Ausgangssignal. Zu Beginn stehen alle Schwellenwerte und Gewichte auf Zufallswerten. Während des Trainings werden sie an die Traingsdaten angepasst.\n",
            "In der Regel werden die Neuronen in Schichten zusammengefasst. Die Signale wandern von der ersten Schicht (der Eingabeschicht) zur letzten Schicht (der Ausgabeschicht) und durchlaufen dabei möglicherweise mehrere Zwischenschichten (versteckte Schichten). Ein Netz wird als tiefes neuronales Netz bezeichnet, wenn es mindestens 2 versteckte Schichten hat. Darauf bezieht sich auch der Begriff Deep Learning. Jede Schicht kann die Signale an ihren Eingängen unterschiedlich transformieren.[17] Siehe auch Convolutional Neural Network.\n",
            "Generative Adversarial Networks[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Generative Adversarial Networks\n",
            "Schematische Darstellung eines Generative Adversarial Networks.\n",
            "Generative Adversarial Networks (GAN) ist die Bezeichnung für eine Klasse von maschinellen Lernverfahren, die Netzwerke im Kontext von generativem Lernen bzw. unüberwachtem Lernen trainieren. Ein GAN besteht aus zwei künstlichen neuronalen Netzwerken, die ein Nullsummenspiel durchführen. Das Modell lernt aus einem Trainingsdatensatz, neue Daten zu erzeugen, deren Eigenschaften denen der Trainingsdaten gleichen. Beispielsweise kann ein GAN, das mit Fotografien trainiert wurde, neue Fotografien erzeugen, die für menschliche Betrachter zumindest oberflächlich authentisch aussehen und viele realistische Merkmale aufweisen. Obwohl sie ursprünglich als generatives Modell für unüberwachtes Lernen vorgeschlagen wurden, haben sich GAN auch für teilüberwachtes Lernen, überwachtes Lernen und bestärkendes Lernen als nützlich erwiesen.\n",
            "GAN sind ein wichtiger Baustein für die Entwicklung einer generativen künstlichen Intelligenz. Das ist die Bezeichnung für eine künstliche Intelligenz, die in der Lage ist, Texte, Bilder oder andere Daten mit Hilfe generativer Modelle zu erzeugen, oft als Reaktion auf Benutzeranfragen.\n",
            "Automatisiertes Maschinelles Lernen[Bearbeiten | Quelltext bearbeiten]\n",
            "→ Hauptartikel: Automatisiertes maschinelles Lernen\n",
            "Das Ziel des automatisierten maschinellen Lernens besteht darin, alle Arbeitsschritte zu automatisieren. Dazu gehören die Auswahl eines geeigneten Modells und die Anpassung seiner Hyperparameter.[11]:383\n",
            "Siehe auch[Bearbeiten | Quelltext bearbeiten]\n",
            "Commons: Maschinelles Lernen – Sammlung von Bildern, Videos und Audiodateien\n",
            "Föderales Lernen\n",
            "Empirische Risikominimierung\n",
            "Transfer Learning\n",
            "Literatur[Bearbeiten | Quelltext bearbeiten]\n",
            "Andreas C. Müller, Sarah Guido: Einführung in Machine Learning mit Python. O’Reilly-Verlag, Heidelberg 2017, ISBN 978-3-96009-049-6. \n",
            "Christopher M. Bishop: Pattern Recognition and Machine Learning. Information Science and Statistics. Springer-Verlag, Berlin 2008, ISBN 978-0-387-31073-2. \n",
            "David J. C. MacKay: Information Theory, Inference and Learning Algorithms. Cambridge University Press, Cambridge 2003, ISBN 0-521-64298-1 (Online). \n",
            "Trevor Hastie, Robert Tibshirani, Jerome Friedman: The Elements of Statistical Learning. Data Mining, Inference, and Prediction. 2. Auflage. Springer-Verlag, 2008, ISBN 978-0-387-84857-0 (stanford.edu [PDF]). \n",
            "Thomas Mitchell: Machine Learning. Mcgraw-Hill, London 1997, ISBN 0-07-115467-1. \n",
            "D. Michie, D. J. Spiegelhalter: Machine Learning, Neural and Statistical Classification. In: Ellis Horwood Series in Artificial Intelligence. E. Horwood Verlag, New York 1994, ISBN 0-13-106360-X. \n",
            "Richard O. Duda, Peter E. Hart, David G. Stork: Pattern Classification. Wiley, New York 2001, ISBN 0-471-05669-3. \n",
            "David Barber: Bayesian Reasoning and Machine Learning. Cambridge University Press, Cambridge 2012, ISBN 978-0-521-51814-7. \n",
            "Arthur L. Samuel (1959): Some studies in machine learning using the game of checkers. IBM J Res Dev 3:210–229. doi:10.1147/rd.33.0210.\n",
            "Alexander L. Fradkov: Early History of Machine Learning. IFAC-PapersOnLine, Volume 53, Issue 2, 2020, Pages 1385-1390, doi:10.1016/j.ifacol.2020.12.1888.\n",
            "Weblinks[Bearbeiten | Quelltext bearbeiten]\n",
            "Machine Learning Crash Course. In: developers.google.com. Abgerufen am 6. November 2018 (englisch). \n",
            "Heinrich Vasce: Machine Learning - Grundlagen. In: Computerwoche. 13. Juli 2017, abgerufen am 16. Januar 2019. \n",
            "golem.de, Miroslav Stimac: So steigen Entwickler in Machine Learning ein, 12. November 2018\n",
            "Introduction to Machine Learning (englisch)\n",
            "Maschinen lernen – ohne Verstand ans Ziel, Wissenschaftsfeature, Deutschlandfunk, 10. April 2016. Audio, Manuskript\n",
            "Einzelnachweise[Bearbeiten | Quelltext bearbeiten]\n",
            "↑ Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani: An Introduction to Statistical Learning. Springer, 2013, S. vii (englisch, bcf.usc.edu (Memento des Originals vom 23. Juni 2019 im Internet Archive) [abgerufen am 17. Februar 2024]). \n",
            "↑ a b c Jörg Frochte: Maschinelles Lernen - Grundlagen und Algorithmen in Python. 3. Auflage. Carl Hanser, München 2021, ISBN 978-3-446-46144-4, S. 21–27. \n",
            "↑ a b Pat Langley: The changing science of machine learning. In: Machine Learning. Band 82, Nr. 3, 18. Februar 2011, S. 275–279, doi:10.1007/s10994-011-5242-y. \n",
            "↑ Danilo Bzdok, Naomi Altman, Martin Krzywinski: Statistics versus Machine Learning. In: Nature Methods. 15. Jahrgang, Nr. 4, 2018, S. 233–234, doi:10.1038/nmeth.4642, PMID 30100822, PMC 6082636 (freier Volltext) – (englisch). \n",
            "↑ a b What is Machine Learning? In: IBM. Abgerufen am 14. Februar 2024 (amerikanisches Englisch). \n",
            "↑ Ralf Otte: Künstliche Intelligenz für Dummies. 1. Auflage. WILEY, Weinheim 2019, ISBN 978-3-527-71494-0, S. 57. \n",
            "↑ ftp://ftp.sas.com/pub/neural/FAQ.html#questions\n",
            "↑ Tobias Reitmaier: Aktives Lernen für Klassifikationsprobleme unter der Nutzung von Strukturinformationen. kassel university press, Kassel 2015, ISBN 978-3-86219-999-0, S. 1 (Google books). \n",
            "↑ Lillian Pierson: Data Science für Dummies. 1. Auflage. Wiley-VCH Verlag, Weinheim 2016, ISBN 978-3-527-80675-1, S. 105 f. (Google books). \n",
            "↑ Ralf Mikut: Data Mining in der Medizin und Medizintechnik. KIT Scientific Publishing, 2008, ISBN 978-3-86644-253-5, S. 34 (Google books). \n",
            "↑ a b c d e Aurélien Géron: Praxiseinstieg Machine Learning. 3. Auflage. dpunkt Verlag, Heidelberg 2023, ISBN 978-3-96009-212-4, S. 42–43. \n",
            "↑ Paul Fischer: Algorithmisches Lernen. Springer-Verlag, 2013, ISBN 978-3-663-11956-2, S. 6–7 (Google books). \n",
            "↑ Richard S. Sutton: Reinforcement learning : an introduction. Second edition Auflage. Cambridge, Massachusetts 2018, ISBN 978-0-262-03924-6. \n",
            "↑ Machine Learning: Definition, Algorithmen, Methoden und Beispiele. 11. August 2020, abgerufen am 31. Januar 2022. \n",
            "↑ Marco Wiering, Martijn van Otterlo: Reinforcement learning : state-of-the-art. Springer, Berlin 2012, ISBN 978-3-642-27645-3. \n",
            "↑ ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles\n",
            "↑ Larry Hardesty: Explained: Neural networks. MIT News Office, 14. April 2017, abgerufen am 20. Februar 2024 (englisch). \n",
            "Normdaten (Sachbegriff): GND: 4193754-5 (lobid, OGND, AKS) \n",
            "Abgerufen von „https://de.wikipedia.org/w/index.php?title=Maschinelles_Lernen&oldid=243101480“\n",
            "Kategorien: NeuroinformatikMaschinelles LernenMultivariate StatistikKlassifizierung\n",
            "Navigationsmenü\n",
            "Meine Werkzeuge\n",
            "Nicht angemeldetDiskussionsseiteBeiträgeBenutzerkonto erstellenAnmelden\n",
            "Namensräume\n",
            "ArtikelDiskussion\n",
            "Deutsch\n",
            "Ansichten\n",
            "LesenBearbeitenQuelltext bearbeitenVersionsgeschichte\n",
            "Weitere\n",
            "Suche\n",
            "Navigation\n",
            "HauptseiteThemenportaleZufälliger Artikel\n",
            "Mitmachen\n",
            "Artikel verbessernNeuen Artikel anlegenAutorenportalHilfeLetzte ÄnderungenKontaktSpenden\n",
            "Werkzeuge\n",
            "Links auf diese SeiteÄnderungen an verlinkten SeitenSpezialseitenPermanenter LinkSeiten­­informationenArtikel zitierenKurzlinkQR-Code herunterladenWikidata-Datenobjekt\n",
            "Drucken/​exportieren\n",
            "Buch erstellenAls PDF herunterladenDruckversion\n",
            "In anderen Projekten\n",
            "Commons\n",
            "In anderen Sprachen\n",
            "Afrikaansالعربيةالدارجةঅসমীয়াAzərbaycancaتۆرکجهБеларускаяБългарскиभोजपुरीবাংলাབོད་ཡིགBosanskiCatalàکوردیČeštinaCymraegDanskΕλληνικάEnglishEspañolEestiEuskaraفارسیSuomiVõroFrançaisGalegoGaelgעבריתहिन्दीMagyarՀայերենBahasa IndonesiaÍslenskaItaliano日本語ქართულიಕನ್ನಡ한국어LietuviųLatviešuМакедонскиമലയാളംМонголमराठीBahasa MelayuNederlandsNorsk nynorskNorsk bokmålOccitanଓଡ଼ିଆPolskiپنجابیپښتوPortuguêsRuna SimiRomânăРусскийᱥᱟᱱᱛᱟᱲᱤSrpskohrvatski / српскохрватскиSimple EnglishSlovenščinaShqipСрпски / srpskiSvenskaதமிழ்తెలుగుไทยTagalogTürkçeئۇيغۇرچە / UyghurcheУкраїнськаاردوOʻzbekcha / ўзбекчаTiếng Việt吴语中文Bân-lâm-gú粵語IsiZulu\n",
            "Links bearbeiten\n",
            " Diese Seite wurde zuletzt am 14. März 2024 um 11:57 Uhr bearbeitet.\n",
            "Abrufstatistik · Autoren \n",
            "Der Text ist unter der Lizenz „Creative-Commons Namensnennung – Weitergabe unter gleichen Bedingungen“ verfügbar; Informationen zu den Urhebern und zum Lizenzstatus eingebundener Mediendateien (etwa Bilder oder Videos) können im Regelfall durch Anklicken dieser abgerufen werden. Möglicherweise unterliegen die Inhalte jeweils zusätzlichen Bedingungen. Durch die Nutzung dieser Website erklären Sie sich mit den Nutzungsbedingungen und der Datenschutzrichtlinie einverstanden.\n",
            "Wikipedia® ist eine eingetragene Marke der Wikimedia Foundation Inc.\n",
            "Datenschutz\n",
            "Über Wikipedia\n",
            "Impressum\n",
            "Verhaltenskodex\n",
            "Entwickler\n",
            "Statistiken\n",
            "Stellungnahme zu Cookies\n",
            "Mobile Ansicht\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dokument 1: {dokumente[0].page_content}\\n\\n\")\n",
        "print(f\"Dokument 2: {dokumente[1].page_content}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:52.663239Z",
          "start_time": "2023-12-22T21:34:52.645034Z"
        },
        "id": "f7c70f596618511b",
        "outputId": "870e68d2-ecc3-44b7-e3a1-83ece8484982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f7c70f596618511b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Daten bereinigen\n",
        "\n",
        "Wie wir feststellen, sehen die Abschnitte noch nicht sehr schön aus. Wir könnten sie bereinigen, indem wir Sonderzeichen entfernen, fehlende Abstände einfügen, etc. Dies wäre aber ein ziemlicher Aufwand und wir allen es in diesem Workshop weg. Wenn wir aber künftig eine noch bessere Chat-Qualität wollen, könnten wir dies noch nachholen.\n",
        "\n",
        "## Grosse Datenmengen\n",
        "\n",
        "Wir haben nun sehr viel Text eingelesen. Leider können AI Chatbots nur mit einer begrenzten Menge an Text arbeiten. Wir müssen also die Datenmenge reduzieren. Dies können wir machen, indem wir die Texte in kleinere Abschnitte aufteilen. Nachfolgender Code teilt die Texte in Abschnitte von 1000 Zeichen auf, wobei die Abschnitte sich um 200 Zeichen überlappen. Später wählen wir dann die \"besten\" Abschnitte aus und übergeben sie dem Chatbot.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ea9c529e7ce222e8"
      },
      "id": "ea9c529e7ce222e8"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wir haben unsere Dokumente in 167 Texte aufgeteilt.\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
        "texte = text_splitter.split_documents(dokumente)\n",
        "print(f\"Wir haben unsere Dokumente in {len(texte)} Texte aufgeteilt.\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:34:52.713800Z",
          "start_time": "2023-12-22T21:34:52.657473Z"
        },
        "id": "7c8dbd44aa86c1a9",
        "outputId": "2cbbbdf3-d0a9-4fb7-b7c3-41516e194b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7c8dbd44aa86c1a9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passendste Texte finden\n",
        "\n",
        "Denn passendsten Text direkt zu finden ist sehr schwierig. Wir können aber die passendsten Texte finden, indem wir die Texte mit einer Frage vergleichen. Dazu müssen wir die Texte in Vektoren umwandeln. Ein Vektor ist eine numerische Repräsentation eines Textes. Wir können dann die Ähnlichkeit zwischen der Frage und den Texten berechnen. Die Texte mit der höchsten Ähnlichkeit sollten dann die passendsten Texte sein.\n",
        "\n",
        "Zur Umwandlung der Texte in Vektoren verwenden wir ein Embedding-Modell von Hugging Face. Dieses Modell wurde mit sehr vielen Texten trainiert und kann daher Texte in Vektoren umwandeln."
      ],
      "metadata": {
        "collapsed": false,
        "id": "5d85e8ab73a8ff27"
      },
      "id": "5d85e8ab73a8ff27"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "outputs": [],
      "source": [
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:17.208537Z",
          "start_time": "2023-12-22T21:34:52.677952Z"
        },
        "id": "2181841106b2b138"
      },
      "id": "2181841106b2b138"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embeddings\n",
        "\n",
        "Nachfolgender Code wandelt einen Text in einen Vektor um. Wir können den Code ausführen und sehen, was passiert."
      ],
      "metadata": {
        "collapsed": false,
        "id": "bc0ddda28e25a608"
      },
      "id": "bc0ddda28e25a608"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Der Text ist Geschichtete Repräsentation von Bildern auf mehreren Abstraktionsebenen[1]\n",
            "Deep Learning (deutsch: mehrschichtiges Lernen, tiefes Lernen[2] oder tiefgehendes Lernen) bezeichnet eine Methode des maschinellen Lernens, die künstliche neuronale Netze (KNN) mit zahlreichen Zwischenschichten (englisch hidden layers) zwischen Eingabeschicht und Ausgabeschicht einsetzt und dadurch eine umfangreiche innere Struktur herausbildet.[3][4][5] Es ist eine spezielle Methode der Informationsverarbeitung.\n",
            "\n",
            "\n",
            "Das dazugehörige Embedding besteht aus 384 Zahlen.\n",
            "\n",
            "\n",
            "Die Embeddings sind: [-0.014185012318193913, -0.03948082774877548, -0.05409707501530647, 0.08260055631399155, 0.0017176567343994975, 0.005088570527732372, -0.034705258905887604, 0.011471837759017944, -0.027410613372921944, 0.0015370505861938, -0.002251206897199154, -0.037350133061409, -0.011892452836036682, 0.006406981498003006, -0.024514252319931984, 0.054362352937459946, -0.05907692387700081, 0.14670012891292572, -0.0030393428169190884, -0.029841627925634384, 0.010041162371635437, 0.05152126029133797, -0.00328049180097878, 0.02683396451175213, 0.01253663469105959, -0.009041029959917068, -0.05656048655509949, 0.026923181489109993, 0.040167856961488724, -0.052569642663002014, -0.10124705731868744, -0.0696539431810379, 0.011938774958252907, -0.019849175587296486, 0.04526817053556442, -0.050796475261449814, 0.014103379100561142, 0.033147234469652176, -0.02261621132493019, 0.007478647865355015, -0.0026940843090415, 0.08975664526224136, -0.029701609164476395, -0.03454619273543358, 0.055644966661930084, 0.08745266497135162, -0.010941931046545506, 0.06205899640917778, 0.004082974512130022, -0.027221957221627235, -0.04857727140188217, -0.010125910863280296, -0.03679186478257179, -0.052595146000385284, 0.038140084594488144, -0.0066920495592057705, -0.0059840795584023, -0.011706147342920303, -0.015515873208642006, 0.09417645633220673, 0.02744036726653576, -0.056996144354343414, -0.011777859181165695, 0.014628402888774872, -0.02068399079144001, -0.0017996118403971195, -0.03984367102384567, -0.011933972127735615, -0.01093312632292509, -0.03698092699050903, -0.0004567330761346966, 0.0037977697793394327, 0.020542694255709648, 0.03468755632638931, 0.017302818596363068, 0.1497657746076584, 0.04802122339606285, -0.009553053416311741, -0.0751744881272316, -0.10883214324712753, 0.028770016506314278, 0.00985115859657526, 0.06457652151584625, 0.01206898782402277, 0.023545540869235992, 0.10229688882827759, -0.042319972068071365, -0.010444491170346737, 0.004020345397293568, -0.04111630842089653, -0.04204418510198593, -0.06315798312425613, -0.03538006171584129, -0.07842092216014862, 0.017779776826500893, -0.06294460594654083, -0.057027049362659454, -0.014452260918915272, -0.0269395150244236, 0.04615636169910431, 0.031038798391819, -0.062016770243644714, 0.019556144252419472, -0.012218785472214222, 0.013622594997286797, 0.022799547761678696, -0.04115687683224678, -0.026463299989700317, -0.024144914001226425, 0.001481379265896976, 0.05248119682073593, -0.010524674318730831, -0.022633032873272896, 0.019503364339470863, 0.10446397960186005, -0.05145643278956413, 0.021068649366497993, -0.07587803155183792, 0.012778117321431637, 0.030628236010670662, -0.16165733337402344, -0.035101816058158875, 0.03825830668210983, 0.03416834771633148, -0.026077616959810257, -0.021740665659308434, -0.06206897646188736, 0.01759931445121765, 0.02747507020831108, 0.07806923985481262, -0.05808383971452713, -0.022895144298672676, 0.005653643049299717, -0.0023880675435066223, 0.06501782685518265, -0.033589061349630356, -0.05232088640332222, 0.07673560827970505, -0.037723395973443985, 0.07290740311145782, -0.03295622020959854, 0.13642708957195282, 0.11131835728883743, 0.012383133172988892, -0.024478726089000702, -0.015309609472751617, 0.06410786509513855, -0.058572519570589066, 0.009372295811772346, 0.044331151992082596, 0.0026495361234992743, -0.12948301434516907, 0.009672609157860279, 0.0014398270286619663, -0.01810113713145256, -0.03748021647334099, -0.02456771209836006, 0.007144569419324398, -0.05186527967453003, -0.005209296476095915, 0.03925054892897606, 0.07682527601718903, 0.0596836619079113, -0.002665420528501272, 0.001991098513826728, -0.014550594612956047, 0.04483990743756294, -0.007168722804635763, 0.027826178818941116, -0.006359423976391554, -0.07147172093391418, 0.03573349490761757, 0.0256901066750288, 0.033895786851644516, -0.04890832677483559, 0.03315403684973717, -0.10343241691589355, -0.06834790110588074, -0.0300463680177927, -0.025683477520942688, 0.004615480545908213, -0.10233528167009354, -0.011601499281823635, 0.01872730627655983, -0.02195778861641884, 0.031108375638723373, 0.03231821954250336, 0.05476071685552597, -0.033694397658109665, -0.022660287097096443, -0.051248639822006226, 0.006123916711658239, -0.05960940197110176, 0.05646849423646927, 0.039552025496959686, -0.06265589594841003, 0.014610488899052143, -0.03603449836373329, -0.050017960369586945, 0.011169061064720154, -0.06665212661027908, -0.00266662216745317, -0.04203132167458534, 0.01833091862499714, -0.15806274116039276, -0.03703891485929489, -0.032380521297454834, 0.10335832834243774, 0.03116866573691368, 0.0853920578956604, 0.03156697750091553, -0.002042971784248948, -0.07579205930233002, -0.01851675845682621, 0.0391649566590786, 0.03866610676050186, -0.026336144655942917, 0.034825704991817474, -0.07051447033882141, -0.016424981877207756, 0.021417049691081047, -0.004959774669259787, 0.010346883907914162, -1.6491987377364992e-33, -0.09438628703355789, 0.026974868029356003, -0.06937803328037262, 0.11282234638929367, -0.06053398549556732, -0.013141614384949207, -0.09256241470575333, 0.06813722103834152, -0.05211254209280014, 0.012957477010786533, 0.007190014701336622, 0.004490857478231192, -0.008211321197450161, 0.0026443866081535816, 0.04987000674009323, -0.018862716853618622, -0.09562566876411438, 0.024827446788549423, 0.017496395856142044, -0.006179704796522856, -0.040123745799064636, 0.029241396114230156, -0.037011828273534775, 0.010017341934144497, 0.007654991466552019, 0.020628448575735092, -0.019359882920980453, 0.018041297793388367, -0.042781516909599304, 0.020603349432349205, -0.024221468716859818, -0.058631155639886856, 0.0417182631790638, -0.011553068645298481, 0.023534730076789856, 0.08776445686817169, 0.03724025934934616, -0.008380585350096226, -0.03949877619743347, -0.06482881307601929, 0.05063413456082344, 0.041599418967962265, -0.06751900166273117, -0.03455081582069397, -0.03332901373505592, -0.09185265749692917, -0.09777567535638809, -0.09168031066656113, -0.02895505167543888, 0.03797103092074394, 0.0386103019118309, -0.03043273091316223, -0.061547890305519104, -0.061779219657182693, -0.05205057933926582, -0.024917537346482277, -0.00662137009203434, 0.022002220153808594, 0.04449404403567314, 0.060320012271404266, -0.013112827204167843, -0.10198608040809631, -0.011933592148125172, 0.01999003440141678, 0.032890405505895615, 0.03472878038883209, -0.033494964241981506, 0.06982145458459854, -0.014820190146565437, 0.06396544724702835, 0.10502329468727112, 0.10435005277395248, 0.05945626646280289, -0.061044517904520035, -0.039407722651958466, 0.020835109055042267, 0.023561539128422737, -0.029479825869202614, -0.051314450800418854, 0.04249119013547897, 0.028298040851950645, -0.09292279928922653, -0.01408732682466507, 0.026248734444379807, 0.09274425357580185, 0.0812210738658905, -0.019035739824175835, -0.03428560122847557, 0.0039830924943089485, -0.07361623644828796, 0.06182187423110008, -0.06526990234851837, -0.006722795311361551, 0.003752069780603051, -0.023409811779856682, 9.331013031121075e-32, 0.0893111601471901, 0.12486506253480911, 0.021037835627794266, 0.04546429216861725, 0.049664247781038284, -0.046755243092775345, 0.01641317456960678, 0.09922898560762405, -0.06388340890407562, 0.09334219247102737, 0.0263284370303154, -0.047847308218479156, 0.07034242153167725, 0.0617852509021759, 0.08427790552377701, 0.015414326451718807, 0.028181472793221474, 0.04910401254892349, 0.023773817345499992, -0.07216458022594452, 0.09072083979845047, 0.061358414590358734, -0.024792365729808807, -0.09898139536380768, 0.06483466178178787, -0.07189266383647919, -0.04603716358542442, 0.08873350918292999, -0.09419698268175125, 0.03215954452753067, -0.034905124455690384, -0.01767450012266636, 0.05179927498102188, 0.03104948252439499, 0.019388344138860703, 0.09469128400087357, -0.03247468173503876, -0.0011658626608550549, -0.0731789842247963, -0.05334509536623955, -0.019473491236567497, -0.017730960622429848, 0.059028178453445435, -0.024452069774270058, -0.026847945526242256, 0.04647234454751015, 0.05562513321638107, -0.004693734459578991, 0.012793413363397121, 0.03852028399705887, -0.037387195974588394, 0.018096571788191795, 0.027851514518260956, -0.05611336976289749, 0.02739700861275196, 0.07547664642333984, -0.02297980524599552, -0.08387746661901474, -0.07038380205631256, 0.0346553809940815, -0.07319709658622742, -0.028891973197460175, 0.019507160410284996, -0.11988116055727005]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = texte[1].page_content\n",
        "embeddings = embedding_model.embed_query(text)\n",
        "print(f\"Der Text ist {text}\\n\\n\")\n",
        "print(f\"Das dazugehörige Embedding besteht aus {len(embeddings)} Zahlen.\\n\\n\")\n",
        "print(f\"Die Embeddings sind: {embeddings}\\n\\n\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:18.976064Z",
          "start_time": "2023-12-22T21:35:17.211835Z"
        },
        "id": "ed6cfbba4dbf50af",
        "outputId": "3cfbc75a-19a7-4656-c596-0b8a15c44d19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ed6cfbba4dbf50af"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Ähnlichkeit berechnen\n",
        "\n",
        "Wir können nicht nur unsere Texte in Vektoren umwandeln, sondern auch unsere Frage. Nachfolgender Code wandelt einige Fragen in Vektoren um.\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7ee3b5c90925b70b"
      },
      "id": "7ee3b5c90925b70b"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04565805196762085, 0.03119267337024212, 0.0034045418724417686, -0.007587556727230549, 0.09747792780399323, 0.016057834029197693, 0.06088406965136528, -0.0007447446696460247, -0.01949154958128929, 0.05100805312395096, 0.018386652693152428, -0.03461936116218567, -0.02988843433558941, 0.016160761937499046, 0.008028628304600716, 0.06239267811179161, 0.00575797026976943, 0.05787547677755356, 0.03145628795027733, 0.02753416635096073, 0.060553256422281265, 0.06716932356357574, 0.022254012525081635, 0.04500420391559601, 0.007381688803434372, -0.03401831537485123, -0.06774533540010452, 0.038843072950839996, -0.02074025385081768, -0.017202330753207207, 0.00772966630756855, -0.00279031740501523, -0.022588269785046577, 0.010966111905872822, 0.06083492934703827, -0.00010078286868520081, 0.04051096737384796, 0.01109327469021082, 0.01773117296397686, 0.03108968213200569, -0.052715547382831573, 0.04472431540489197, 0.02681240811944008, 0.0006068079965189099, 0.04354388639330864, 0.01326124556362629, -0.0163300521671772, 0.05992943421006203, 0.004533632192760706, -0.0009916616836562753, -0.020121566951274872, -0.00022733151854481548, 0.0026001078076660633, -0.07422970235347748, -0.01652463525533676, 0.0027602477930486202, -0.032503314316272736, -0.14415262639522552, -0.034198686480522156, 0.07029253989458084, -0.02447499707341194, -0.031147293746471405, -0.09309065341949463, -0.03252275288105011, -0.06968563050031662, 0.01675993762910366, 0.00218090508133173, 0.02787785418331623, -0.042547617107629776, 0.007272535469383001, -0.0030384869314730167, -0.06525760889053345, 0.0043627298437058926, -0.04247261583805084, 0.02900814451277256, 0.03724030405282974, 0.007777783554047346, -0.024534717202186584, -0.07996676117181778, -0.05858251824975014, -0.08627986162900925, -0.07221385836601257, 0.05164783447980881, -0.029535405337810516, -0.052039746195077896, 0.07038286328315735, -0.044391125440597534, 0.03662026301026344, 0.08207724243402481, -0.014878986403346062, 0.03015316091477871, 0.011446782387793064, -0.0339159220457077, -0.08963698148727417, -0.043240971863269806, 0.023468652740120888, 0.08713249117136002, -0.021027682349085808, -0.13545159995555878, 0.060429856181144714, -0.05427645891904831, 0.0008515119552612305, 0.0005277115269564092, 0.021221650764346123, -0.041195210069417953, 0.027020785957574844, 0.01859091967344284, -0.010850480757653713, -0.09720637649297714, -0.021123191341757774, 0.0892716720700264, 0.03434516862034798, -0.12232283502817154, 0.07267154008150101, -0.011133351363241673, 0.0074681551195681095, -0.029675845056772232, -0.020692845806479454, 0.05886237323284149, 0.007211864925920963, -0.06061500310897827, 0.0754157304763794, 0.055334728211164474, 0.0032158063258975744, -0.026787709444761276, -0.10513563454151154, -0.058496374636888504, 0.06901907920837402, 0.04843887314200401, 0.1588914841413498, -0.020072566345334053, 0.0015603959327563643, 0.0604141466319561, -0.015800470486283302, 0.06820189952850342, -0.023176729679107666, -0.026337940245866776, 0.08143793791532516, 0.04349173605442047, -0.029331091791391373, -0.03999485820531845, 0.013714972883462906, 0.09916828572750092, -0.027724385261535645, 0.016466643661260605, -0.019670551642775536, 0.11789022386074066, -0.031165942549705505, -0.000809497432783246, 0.050873544067144394, 0.01156179141253233, -0.15929140150547028, 0.034940097481012344, 0.035578832030296326, 0.06105276197195053, 0.023854296654462814, -0.08070538938045502, 0.051858626306056976, 0.03437935560941696, -0.011393235996365547, -0.007168002892285585, 0.06731473654508591, -0.0018423172878101468, -0.017419567331671715, 0.004111909307539463, 0.029004383832216263, 0.013380724936723709, 0.06053970754146576, -0.03238159045577049, -0.005173226352781057, -0.05516209080815315, 0.008025148883461952, -0.06624668836593628, 0.09122289717197418, -0.011785056442022324, 0.01213721465319395, -0.0602349117398262, -0.03840499371290207, -0.028295831754803658, 0.0354226715862751, 0.06905152648687363, -0.038652412593364716, -0.00904701929539442, -0.012237844988703728, -0.05889272689819336, -0.018677201122045517, -0.018056944012641907, -0.01097088772803545, 0.005274899769574404, 0.04070904478430748, -0.037754472345113754, 0.05435500293970108, -0.03424956649541855, -0.024759644642472267, 0.025660846382379532, -0.07173679023981094, 0.034723248332738876, 0.05811353027820587, -0.07610523700714111, -0.014297043904662132, 0.03352181613445282, 0.023012788966298103, -0.03247435390949249, 0.011257569305598736, -0.04611342027783394, 0.01598653756082058, -0.01793784461915493, 0.009018057957291603, 0.0641903355717659, 0.032990697771310806, 0.013396481052041054, -0.047474514693021774, -0.035625312477350235, -0.0077922712080180645, 0.07745220512151718, 0.08048874884843826, -0.010773849673569202, -0.02986251749098301, -0.048727281391620636, -0.05336588993668556, 0.0393562912940979, -0.002804933814331889, -0.03921673074364662, 6.845344415219739e-33, -0.06048601493239403, -0.021931035444140434, -0.03342059627175331, 0.01051438320428133, 0.0017718622693791986, -0.011438055895268917, -0.06665624678134918, -0.07599947601556778, -0.02073843404650688, -0.00031008737278170884, 0.02725779451429844, 0.0005754186422564089, 0.020102525129914284, 0.04906999319791794, 0.018820980563759804, -0.08256680518388748, 0.013350050896406174, 0.033461980521678925, -0.05680089443922043, -0.014543804340064526, -0.02572980336844921, 0.0880420058965683, 0.022036056965589523, 0.04530452936887741, 0.05820506811141968, 0.03813958540558815, 0.01819254271686077, 0.004988588858395815, -0.11224932223558426, 0.05132371932268143, 0.040173545479774475, -0.1202533170580864, 0.0867643877863884, -0.00907024648040533, 0.07534223049879074, 0.021199867129325867, 0.05991414561867714, -0.00558045320212841, -0.0006027776398696005, 0.015346573665738106, -0.02198307029902935, 0.05639626458287239, -0.05294220894575119, 0.022966716438531876, -0.0416911244392395, -0.01241859421133995, -0.045608021318912506, -0.028690848499536514, 0.029688427224755287, -0.009930412285029888, -0.006586355622857809, -0.009483126923441887, 0.05699931085109711, -0.14538109302520752, -0.005360275972634554, -0.044001951813697815, -0.08239979296922684, -0.016143934801220894, -0.013659212738275528, 0.0673808753490448, 0.026781393215060234, -0.04616985842585564, -0.04150465130805969, -0.037241075187921524, 0.09549189358949661, -0.009778143838047981, -0.013952184468507767, -0.0401492677628994, 0.04275780916213989, 0.09439050406217575, 0.07119175791740417, 0.09878058731555939, -0.01761450618505478, 0.06452007591724396, -0.018956491723656654, -0.010901215486228466, 0.08011535555124283, -0.08266448229551315, -0.05437646433711052, 0.06743627786636353, -0.0003237857308704406, -0.1118600070476532, 0.010908749885857105, -0.02886056713759899, 0.07441767305135727, -0.030695099383592606, 0.02413877286016941, -0.008312937803566456, -0.04080839082598686, -0.035733532160520554, 0.073050856590271, -0.027993695810437202, 0.06229890510439873, -0.05084154009819031, 0.005598141346126795, 3.6253206745991144e-32, 0.12044620513916016, 0.014941917732357979, -0.01604207046329975, -0.01647782139480114, -0.043512336909770966, -0.012446515262126923, 0.04965256527066231, 0.073424331843853, -0.01802302896976471, 0.10689850896596909, 0.015138662420213223, -0.06107758730649948, 0.0425463505089283, 0.06271765381097794, -0.04128757491707802, -0.04689780995249748, 0.07798945903778076, 0.05437932536005974, -0.05539731681346893, -0.13593800365924835, 0.05489974841475487, -0.0629565417766571, -0.053007569164037704, -0.13044102489948273, -0.08128713071346283, 0.0037770401686429977, 0.04090530052781105, 0.030815575271844864, -0.04669433459639549, 0.09943858534097672, -0.014250035397708416, -0.07277235388755798, -0.001624651369638741, 0.06684713065624237, 0.017739370465278625, -0.0642516016960144, -0.06440293043851852, -0.008537141606211662, -0.0011141553986817598, -0.07006076723337173, 0.07195983082056046, 0.04233743995428085, 0.024428198114037514, 0.0017627908382564783, 0.03270772099494934, -0.008874430321156979, 0.036966100335121155, 0.022343913093209267, 0.04233960434794426, 0.07467241585254669, -0.09365146607160568, 0.07549352943897247, 0.05447842553257942, -0.055707503110170364, -0.08676271885633469, -0.029825259000062943, 0.06395862996578217, -0.017316853627562523, 0.005034727044403553, -0.02046307548880577, -0.051798053085803986, -0.07615751028060913, 0.017801297828555107, -0.08940701186656952]\n",
            "[-0.015531547367572784, 0.09410204738378525, -0.07676361501216888, 0.03545277565717697, -0.05359077826142311, -0.011709458194673061, 0.006551284808665514, 0.007962781004607677, 0.018380984663963318, 0.010817999951541424, -0.06594886630773544, -0.0022844444029033184, -0.020639972761273384, -0.021547453477978706, 0.11863180994987488, 0.039083804935216904, -0.03154466301202774, 0.03513101488351822, 0.019822143018245697, 0.04302913695573807, 0.06511298567056656, 0.06345100700855255, -0.06227656453847885, -0.009378314018249512, 0.003420482622459531, 0.09466186910867691, -0.057505421340465546, -0.027271714061498642, -0.00418696366250515, -0.02396080642938614, 0.00021196086890995502, -0.03551960363984108, -0.02507033571600914, -0.03511778637766838, 0.08043421059846878, -0.1175922229886055, 0.07441176474094391, 0.02088351547718048, 0.0636909231543541, 0.03081829659640789, 0.001321552088484168, 0.006003180518746376, -0.04029494524002075, -0.0077224732376635075, 0.018076978623867035, -0.021287765353918076, 0.0627940371632576, 0.0822092667222023, 0.0358191542327404, -0.019297145307064056, -0.030848603695631027, -0.010695011354982853, -0.04357660561800003, -0.003305529011413455, -0.009858816862106323, -0.008628803305327892, -0.019450761377811432, -0.043856069445610046, -0.007111249957233667, 0.054140862077474594, 0.003551614936441183, -0.04036129266023636, -0.056929830461740494, 0.06748971343040466, -0.03491725027561188, -0.04978744685649872, 0.014929011464118958, -0.061245717108249664, 0.01739352010190487, -0.005757477600127459, -0.016948772594332695, -0.019496234133839607, 0.04678435996174812, 0.023817267268896103, -0.0007327430648729205, -0.02030847780406475, -0.003131694393232465, 0.022960539907217026, -0.05156141519546509, 0.012998156249523163, -0.07306408882141113, -0.13874398171901703, -0.04666747525334358, 0.0165566299110651, -0.040282126516103745, -0.0705643966794014, -0.005738426931202412, -0.029396560043096542, 0.034860916435718536, 0.0022403402253985405, 0.029123682528734207, -0.015853682532906532, 0.09385398030281067, -0.014596736989915371, 0.04568156227469444, -0.11035630106925964, -0.09071918576955795, 0.041094984859228134, 0.006973428651690483, 0.05623520910739899, 0.03447419032454491, -0.013802912086248398, 0.01860036514699459, 0.09206131100654602, 0.07203923910856247, 0.02558656595647335, -0.05125248432159424, -0.0921003520488739, -0.054749153554439545, 0.011790583841502666, 0.024396851658821106, -0.005781843792647123, -0.0024526549968868494, 0.08256866782903671, 0.009596739895641804, -0.10135876387357712, -0.017921414226293564, -0.012191001325845718, 0.0686691477894783, -0.008009693585336208, -0.033005811274051666, -0.07213841378688812, 0.0704461857676506, -0.00958997942507267, -0.004631969146430492, -0.026648646220564842, -0.0017436709022149444, 0.017694907262921333, -0.0597064271569252, -0.132571280002594, 0.0003164444933645427, -0.12326887249946594, 0.032810140401124954, -0.031005769968032837, -0.04594641178846359, -0.062267884612083435, -0.06098801642656326, 0.0523446761071682, 0.06417740881443024, 0.012339436449110508, 0.016963301226496696, 0.061482805758714676, 0.030869467183947563, 0.051851786673069, -0.013539211824536324, 0.005849955137819052, 0.09811115264892578, 0.08052950352430344, -0.016453368589282036, 0.026088476181030273, 0.15995116531848907, -0.06085609272122383, 0.034607090055942535, 0.08826795965433121, -7.854921568650752e-05, 0.08269649744033813, 0.022960305213928223, 0.032043904066085815, 0.00041364599019289017, 0.03615187108516693, -0.059870827943086624, 0.03327628970146179, -0.009258433245122433, 0.03787679970264435, 0.02409598045051098, -0.001985435374081135, 0.05986301228404045, -0.06508426368236542, 0.09500641375780106, 0.04099196568131447, -0.09318358451128006, -0.12537206709384918, 0.020890982821583748, 0.01878581941127777, 0.020859437063336372, -0.00220802566036582, 0.018823321908712387, -0.01539517380297184, -0.04843951016664505, -0.07796591520309448, 0.10147355496883392, -0.047176849097013474, -0.06390450894832611, 0.027540355920791626, -0.020155662670731544, -0.008497089147567749, -0.014141061343252659, 0.014033504761755466, -0.010892968624830246, 0.10621795058250427, 0.013570754788815975, 0.017429377883672714, 0.09668676555156708, 0.06543682515621185, -0.023926349356770515, -0.03857805207371712, -0.029587119817733765, 0.01416698843240738, -0.07995317876338959, -0.10377300530672073, 0.012479298748075962, 0.08264659345149994, 0.0022152739111334085, 0.019282452762126923, -0.08598091453313828, -0.08798523992300034, -0.0027694471646100283, 0.03779855743050575, 0.04329150542616844, 0.1079244539141655, 0.048457104712724686, -0.04017367213964462, -0.06297030299901962, 0.024728506803512573, -0.0599190816283226, 0.04602832719683647, 0.013260259293019772, 0.07473058253526688, -0.07394877821207047, 0.03761809691786766, 0.023238839581608772, 0.061347126960754395, -0.003941246774047613, 2.506313233141766e-35, -0.04059930518269539, 0.027164267376065254, 0.04393225908279419, -0.04390641301870346, -0.002125595463439822, -0.05361869931221008, -0.07065493613481522, -0.028357436880469322, -0.08331586420536041, 0.06427927315235138, 0.06173791363835335, 0.04267245903611183, 0.05965358018875122, -0.030089519917964935, 0.07526469975709915, 0.005342291202396154, 0.04080013185739517, -0.08477692306041718, 0.0069459727965295315, -0.07407354563474655, 0.04969450458884239, 0.11057097464799881, 0.13262109458446503, 0.017293879762291908, -0.08931039273738861, 0.023539163172245026, 0.0380382239818573, -0.06363730132579803, -0.022559313103556633, -0.04965151846408844, -0.022264426574110985, 0.06300879269838333, 0.03478144854307175, 0.00010366315837018192, 0.07599945366382599, 0.029362238943576813, -0.012066194787621498, 0.045675672590732574, 0.006825618911534548, -0.004222509451210499, -0.03881794214248657, 0.04059061035513878, -0.037261489778757095, 0.02064485102891922, 0.04039636626839638, 0.04474417492747307, 0.021282708272337914, -0.03626429662108421, -0.03268222138285637, -0.011876102536916733, -0.06350024044513702, -0.02410973608493805, -0.07538016140460968, -0.008315718732774258, -0.03820871189236641, 0.006776913534849882, 0.002354524563997984, 0.03292051702737808, 0.04505413770675659, 0.10734399408102036, 0.0699809268116951, -0.03656119108200073, 0.02292885072529316, 0.04907532408833504, 0.0806848406791687, 0.00567872216925025, -0.028872918337583542, -0.12631946802139282, 0.025380445644259453, 0.04939264804124832, 0.047826703637838364, -0.001859751413576305, -0.08246497064828873, -0.04909816384315491, -0.026821400970220566, 0.06192843243479729, -0.0313134603202343, -0.00554312439635396, -0.02736497111618519, 0.0020681514870375395, -0.03591092675924301, -0.026495913043618202, 0.009369529783725739, 0.027881992980837822, -0.08032224327325821, -0.06711367517709732, -0.0005497826496139169, 0.016062118113040924, -0.005586671177297831, -0.11360160261392593, 0.01834416203200817, -0.04975137859582901, -0.025638779625296593, -0.02035263366997242, 0.04849109798669815, 5.045857696173053e-32, 0.007262212224304676, 0.049977678805589676, -0.016856061294674873, 0.07658800482749939, 0.014281547628343105, 0.01647869497537613, -0.06339766085147858, -0.010383762419223785, -0.007722990121692419, 0.02696564607322216, -0.04325881227850914, -0.011264721862971783, -0.005793352611362934, -0.006489510182291269, 0.07966641336679459, 0.011120780371129513, 0.028685031458735466, 0.05564282834529877, 0.0196966752409935, -0.07122547179460526, 0.0552971251308918, -0.010323306545615196, -0.048299018293619156, -0.02004956267774105, -0.06751455366611481, 0.005750189069658518, 0.004744574893265963, 0.024251891300082207, -0.014906203374266624, -0.12006644159555435, -0.012118293903768063, -0.04379037395119667, -0.0008139892597682774, -0.031227150931954384, -0.020428679883480072, -0.1304691880941391, -0.017546886578202248, -0.06962808966636658, 0.024341953918337822, -0.1094907745718956, 0.025075780227780342, -0.04128706827759743, -0.00022603788238484412, -0.0031320969574153423, 0.030008526518940926, 0.056680914014577866, 0.04505425691604614, 0.0009571635164320469, -0.041329145431518555, -0.03337961435317993, -0.049240365624427795, 0.03760853037238121, -0.004049873445183039, -0.06032084301114082, -0.05132752284407616, 0.022926656529307365, 0.02977435290813446, -0.03365601226687431, -0.03332126513123512, 0.09470309317111969, 0.031517405062913895, -0.007897255942225456, -0.047559186816215515, -0.09191176295280457]\n",
            "[-0.005499204155057669, 0.1948811411857605, -0.011526278220117092, 0.04153427109122276, -0.05921657383441925, -0.05231934040784836, 0.08414585888385773, 0.06604611128568649, -0.027802199125289917, -0.02498714253306389, 0.0600278340280056, -0.03982501104474068, 0.04204639419913292, -0.017056599259376526, 0.12809909880161285, 0.003636263543739915, 0.006750424392521381, 0.03281683847308159, -0.0024872333742678165, 0.0694531723856926, -0.06022205203771591, -0.08185935020446777, 0.02794424630701542, 0.033853087574243546, 0.08760663121938705, 0.003049687249585986, 0.0669386088848114, -0.002837234176695347, 0.00047830500989221036, 0.003186747431755066, 0.0454416498541832, -0.0334959402680397, -0.05135326832532883, -0.051352884620428085, 0.04433343932032585, -0.04297957196831703, 0.126839280128479, -0.04867275431752205, 0.00701439194381237, 0.023965617641806602, -0.05852903425693512, -0.018033422529697418, -0.033951226621866226, -0.08543054759502411, 0.03019837476313114, -0.012738185003399849, -0.046271588653326035, 0.05381271615624428, -0.07789219170808792, -0.0455385260283947, -0.045331504195928574, -0.005531521048396826, -0.01558587048202753, 0.0059648980386555195, 0.09222874045372009, -0.06491325050592422, -0.00998938549309969, -0.03169485554099083, 0.002117172349244356, 0.026793496683239937, -0.006669751834124327, 0.0023379698395729065, 0.06138787046074867, 0.01195795089006424, 0.018179502338171005, -0.032182738184928894, 0.06344016641378403, -0.009062043391168118, -0.0008872811449691653, 0.023644475266337395, 0.021851178258657455, -0.06781458109617233, 0.01437036320567131, 0.013654597103595734, 0.0554981455206871, -0.028726795688271523, -0.03344734385609627, -0.04949719458818436, -0.13879166543483734, -0.0260333139449358, 0.010612876154482365, -0.07603948563337326, -0.016463756561279297, -0.020651761442422867, 0.0042333160527050495, 0.053374893963336945, 0.021684138104319572, 0.0009311685571447015, -0.036098890006542206, -0.008834099397063255, 0.006448439322412014, -0.11137568205595016, -0.028668878600001335, 0.02466977946460247, 0.038746219128370285, 0.0021630271803587675, -0.008643059059977531, -0.05634516477584839, -0.04531553015112877, 0.05877096951007843, 0.05536992475390434, -0.11052646487951279, -0.05894969776272774, -0.00472291000187397, 0.013186261989176273, 0.02942236326634884, 0.06763412058353424, 0.011919029988348484, -0.028689252212643623, 0.03156977891921997, -0.09080532938241959, 0.04495792090892792, -0.07161533087491989, 0.12162359058856964, 0.04324891418218613, 0.04748574644327164, 0.07052498310804367, -0.07410267740488052, 0.10458303987979889, -0.0021613093558698893, -0.0006379091064445674, 0.010895081795752048, 0.04671899974346161, -0.002112490823492408, -0.04819723591208458, -0.010136186145246029, 0.01712247170507908, 0.02446094900369644, -0.04955574870109558, -0.01862892508506775, -0.03729614242911339, -0.08519292622804642, -0.03969955071806908, 0.019155314192175865, 0.10326790809631348, -0.018564822152256966, -0.011060926131904125, 0.0007245636079460382, -0.06880532950162888, -0.029050584882497787, 0.050923701375722885, -0.0770462229847908, -0.04775134101510048, -0.06994552165269852, 0.014653261750936508, -0.05784556642174721, 0.06314142793416977, 0.024001428857445717, -0.12935836613178253, -0.004697875585407019, -0.028208784759044647, -0.026236344128847122, 0.03164657577872276, 0.029621295630931854, 0.005742426961660385, -0.04202267900109291, 0.005656992085278034, -0.05942549929022789, 0.1170223280787468, 0.05894016847014427, 0.03837965056300163, 0.08108434081077576, -0.10198773443698883, -0.02935810014605522, -0.008189589716494083, 0.021752452477812767, -0.06792327016592026, -0.009666294790804386, -0.011236213147640228, -0.03460245952010155, 0.009792461059987545, -0.0508885458111763, -0.08087753504514694, 0.1200660914182663, 0.018792670220136642, 0.019967012107372284, -0.036637067794799805, 0.03801700845360756, 0.0010414962889626622, -0.08795959502458572, -0.008864451199769974, 0.010865476913750172, 0.0353068932890892, -0.03615330904722214, -0.040066733956336975, -0.027967236936092377, -0.025460245087742805, 0.019850045442581177, -0.04075989872217178, 0.02905692346394062, 0.04642364755272865, 0.027230657637119293, 0.023938601836562157, 0.0011825254186987877, -0.004143929574638605, 0.026394544169306755, -0.016485650092363358, 0.0702124610543251, -0.08203248679637909, 0.030950140208005905, -0.005714568309485912, 0.012068048119544983, -0.020743003115057945, 0.022871628403663635, -0.01889083720743656, 0.055827539414167404, -0.059592802077531815, 0.009571649134159088, 0.07494668662548065, 0.0006563534261658788, -0.004942785017192364, 0.014262284152209759, -0.08579684048891068, -0.11621788889169693, -0.05846165493130684, -0.025592930614948273, -0.022510113194584846, 0.025395143777132034, -0.06634324789047241, 0.04572628438472748, 0.03539358451962471, -0.004576764535158873, -0.11604566872119904, -6.041986963954817e-33, -0.004792339168488979, 0.027370313182473183, -0.04545704647898674, 0.003344462951645255, 0.045195963233709335, 0.06452462077140808, 0.012142766267061234, 0.00447890954092145, -0.06845691055059433, 0.021481040865182877, -0.01891874149441719, 0.006449041422456503, 0.0566178523004055, -0.04677524045109749, -0.026990508660674095, 0.012531719170510769, 0.04796069487929344, -0.06916338950395584, 0.0028034215793013573, 0.03769560158252716, 0.008073180913925171, 0.03611034154891968, 0.007081812247633934, 0.14708350598812103, -0.0753995031118393, 0.01919197291135788, -0.031009329482913017, -0.06056692451238632, -0.02965620532631874, 0.04922906681895256, 0.04485486447811127, 0.07084120810031891, 0.0910707339644432, -0.05096679553389549, 0.04327363520860672, -0.08543376624584198, 0.0713256224989891, 0.10542032122612, -0.032116398215293884, 0.0024211278650909662, -0.09494652599096298, 0.06965621560811996, -0.04079771786928177, 0.045665837824344635, 0.04234739765524864, -0.04501701891422272, 0.007321998476982117, -0.09852622449398041, 0.06535269320011139, -0.043309446424245834, 0.02044028602540493, -0.02910456247627735, -0.014505133032798767, 0.02153448946774006, 0.03281233832240105, 0.042408376932144165, -0.0675288736820221, -0.019071759656071663, -0.017261967062950134, 0.02661326713860035, 0.043257229030132294, 0.024223657324910164, 0.022824684157967567, 0.0017587356269359589, 0.010678206570446491, -0.004458087496459484, 0.024124300107359886, 0.04733078181743622, -0.08565317094326019, 0.05372736230492592, 0.06502778083086014, -0.06699687242507935, -0.018574560061097145, 0.01656128279864788, -0.0660976842045784, 0.017513008788228035, 0.038203638046979904, 0.014938677661120892, -0.11281722784042358, 0.1277027279138565, 0.03755638748407364, -0.001632845844142139, -0.09340086579322815, -0.08770094811916351, -0.017188122496008873, -0.04436805844306946, 0.05263843014836311, 0.049263615161180496, 0.012193880043923855, 0.06552436947822571, -0.010486322455108166, -0.0003675334737636149, 0.011296410113573074, -0.02670719102025032, -0.005140661261975765, 5.060152295226227e-32, -0.019835831597447395, 0.01896578073501587, -0.01884184032678604, -0.0010276363464072347, -0.07835575938224792, -0.05197995528578758, -0.02352643944323063, -0.029451554641127586, -0.02296433597803116, 0.010726429522037506, 0.04868617653846741, -0.0029240897856652737, -0.05644602328538895, 0.002225692616775632, -0.021975506097078323, 0.006078777369111776, -0.02898874506354332, 0.0326823964715004, -0.04216092452406883, -0.11667279154062271, -0.013490431942045689, -0.025137994438409805, -0.022194113582372665, -0.029299896210432053, -0.0568881519138813, -0.04385918751358986, -0.0564022921025753, 0.06444907933473587, -0.04761963337659836, -0.04728144407272339, 0.038846902549266815, 0.06130831316113472, 0.03493950515985489, -0.012260348536074162, -0.09243644773960114, 0.01521072443574667, 0.05816032737493515, 0.0785551592707634, -0.018609462305903435, -0.006045717746019363, 0.009591452777385712, -0.01829652488231659, 0.01867283135652542, 0.007613626774400473, 0.03483333811163902, 0.10337772965431213, -0.07958149909973145, 0.0017734189750626683, -0.00653033098205924, 0.05018235743045807, -0.012309277430176735, 0.0788554921746254, -0.0034692087210714817, 0.0040399422869086266, 0.07570185512304306, -0.025754816830158234, -0.026281090453267097, -0.0497613325715065, -0.05979233235120773, 0.09473434835672379, 0.009266771376132965, -0.11177700012922287, 0.04135963320732117, 0.08192899078130722]\n"
          ]
        }
      ],
      "source": [
        "embedded_frage_1 = embedding_model.embed_query(\"Ist tiefes Lernen eine Art des maschinellen Lernen?\")\n",
        "print(embedded_frage_1)\n",
        "embedded_frage_2 = embedding_model.embed_query(\"Was ist die Eingangsschicht und die Ausgabeschicht?\")\n",
        "print(embedded_frage_2)\n",
        "embedded_frage_3 = embedding_model.embed_query(\"Trinkt die Kuh Milch oder Wasser?\")\n",
        "print(embedded_frage_3)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:19.136629Z",
          "start_time": "2023-12-22T21:35:18.980505Z"
        },
        "id": "4bb341ba3dc10c38",
        "outputId": "e7945022-c99d-44c3-a243-c89f6353b645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4bb341ba3dc10c38"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir berechnen mithilfe der Kosinus-Ähnlichkeit einen Ähnlichkeitswert zwischen den Fragen und den Texten. Die Kosinus-Ähnlichkeit ist eine Metrik, welche die Ähnlichkeit zwischen zwei Vektoren berechnet. Je höher die Ähnlichkeit, desto ähnlicher sind sich die Vektoren. Nachfolgender Code berechnet die Ähnlichkeit zwischen den Fragen und den Texten."
      ],
      "metadata": {
        "collapsed": false,
        "id": "61ee8392a88a13a7"
      },
      "id": "61ee8392a88a13a7"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44269228120719256\n",
            "0.21822272423074607\n",
            "0.07518472506192456\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "print(cosine_similarity(embeddings, embedded_frage_1))\n",
        "print(cosine_similarity(embeddings, embedded_frage_2))\n",
        "print(cosine_similarity(embeddings, embedded_frage_3))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:19.164219Z",
          "start_time": "2023-12-22T21:35:19.092366Z"
        },
        "id": "10569a3ca81b5ccc",
        "outputId": "ac46ce19-3d5d-4082-e301-b8f673b268cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "10569a3ca81b5ccc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vektoren speichern\n",
        "\n",
        "Das Berechnen der Vektoren ist sehr aufwendig. Wir können die Vektoren aber speichern, so dass wir sie nicht jedes mal neu berechnen müssen. Nachfolgender Code speichert die Vektoren unserer Texte in einer Datenbank, so dass wir künftig nur noch die Vektoren der Frage berechnen müssen.\n",
        "\n",
        "Wir verwenden dazu das Paket `FAISS`. Dieses Paket beinhaltet eine sehr effiziente Datenbank die grosse Datenmengen speichern kann. Zudem kann es sehr schnell die Ähnlichkeit zwischen Vektoren berechnen.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ac86fd3789288c23"
      },
      "id": "ac86fd3789288c23"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "outputs": [],
      "source": [
        "datenbank = FAISS.from_documents(texte, embedding=embedding_model)\n",
        "datenbank.save_local(\"data/index.faiss\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:21.860307Z",
          "start_time": "2023-12-22T21:35:19.103743Z"
        },
        "id": "67901fd069679a26"
      },
      "id": "67901fd069679a26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Texte sind nun in einer Datenbank gespeichert. Wir können sie nun laden und die Ähnlichkeit zwischen den Texten und einer Frage berechnen."
      ],
      "metadata": {
        "collapsed": false,
        "id": "b445f2f0ad247757"
      },
      "id": "b445f2f0ad247757"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='benutzten künstlichen neuronalen Netze sind wie das menschliche Gehirn gebaut, wobei die Neuronen wie ein Netz miteinander verbunden sind. Die erste Schicht des neuronalen Netzes, die sichtbare Eingangsschicht, verarbeitet eine Rohdateneingabe, wie beispielsweise die einzelnen Pixel eines Bildes. Die Dateneingabe enthält Variablen, die der Beobachtung zugänglich sind, daher „sichtbare Schicht“.[3]', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}),\n",
              " Document(page_content='In der Regel werden die Neuronen in Schichten zusammengefasst. Die Signale wandern von der ersten Schicht (der Eingabeschicht) zur letzten Schicht (der Ausgabeschicht) und durchlaufen dabei möglicherweise mehrere Zwischenschichten (versteckte Schichten). Ein Netz wird als tiefes neuronales Netz bezeichnet, wenn es mindestens 2 versteckte Schichten hat. Darauf bezieht sich auch der Begriff Deep Learning. Jede Schicht kann die Signale an ihren Eingängen unterschiedlich transformieren.[17] Siehe', metadata={'source': 'Maschinelles_Lernen', 'title': 'Maschinelles Lernen – Wikipedia'}),\n",
              " Document(page_content='Karl Steinbuchs Lernmatrix[12] war eines der ersten künstlichen neuronalen Netze, das aus mehreren Schichten von Lerneinheiten oder lernenden „Neuronen“ bestand. Damit war er einer der Wegbereiter des Deep Learning, bei dem es um tiefe neuronale Netze geht, die viele Aufgaben erlernen können, bei denen früheren einschichtige Perzeptronen scheitern.', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}),\n",
              " Document(page_content='Künstliche neuronale Netze (KNN) sind Modelle, deren Struktur von biologischen neuronalen Netzen, aus denen Tiergehirne bestehen, inspiriert wurde. Solche Modelle  können aus komplexen und scheinbar zusammenhanglosen Informationen lernen. Einige erfolgreiche Anwendungen sind Bilderkennung und Spracherkennung.', metadata={'source': 'Maschinelles_Lernen', 'title': 'Maschinelles Lernen – Wikipedia'})]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "datenbank.similarity_search(\"Wozu dient die erste Schicht in einem neuronalen Netzwerk?\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:21.946254Z",
          "start_time": "2023-12-22T21:35:21.863873Z"
        },
        "id": "9b8559dc9c1aec71",
        "outputId": "4ff628c7-34ba-4530-d4d5-8991c1b9ec40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9b8559dc9c1aec71"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zwischenfazit\n",
        "\n",
        "Was wir bisher haben:\n",
        "\n",
        "- Wir lesen alle Dokumente von einem Ordner ein\n",
        "- Wir teilen die Dokumente in kleinere Abschnitte auf\n",
        "- Wir wandeln die Abschnitte in Vektoren um\n",
        "- Wir speichern die Vektoren in einer Datenbank\n",
        "- Wir können die Ähnlichkeit zwischen den Vektoren und einer Frage berechnen\n",
        "\n",
        "Was noch fehlt:\n",
        "- Wir müssen die besten Abschnitte auswählen und dem Chatbot übergeben\n",
        "- Wir wollen dem Chatbot eine Frage zum Dokument stellen und eine Antwort erhalten\n",
        "- Der Chatbot soll eine Frage zum Dokument generieren und wir beantworten sie\n",
        "\n",
        "Dazu bilden wir entsprechende Pipelines.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a996ef8353cfb0ab"
      },
      "id": "a996ef8353cfb0ab"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frage beantworten\n",
        "\n",
        "Wir wollen nun eine Frage zum Dokument stellen und eine Antwort erhalten. Dazu müssen wir die Datenbank in die Pipeline einbauen. Die Funktion `datenbank.as_retriever()`erzeugt einen `Retriever`. Dieser Retriever kann für eine gegebene Frage die passendsten Texte finden.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "f8aa7ae1b2966647"
      },
      "id": "f8aa7ae1b2966647"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "outputs": [],
      "source": [
        "retriever = datenbank.as_retriever()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:21.972194Z",
          "start_time": "2023-12-22T21:35:21.947374Z"
        },
        "id": "1608ac7e80f2c637"
      },
      "id": "1608ac7e80f2c637"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dieser Retriever kann wie folgt aufgerufen werden:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1968e402819c5f14"
      },
      "id": "1968e402819c5f14"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Karl Steinbuchs Lernmatrix[12] war eines der ersten künstlichen neuronalen Netze, das aus mehreren Schichten von Lerneinheiten oder lernenden „Neuronen“ bestand. Damit war er einer der Wegbereiter des Deep Learning, bei dem es um tiefe neuronale Netze geht, die viele Aufgaben erlernen können, bei denen früheren einschichtige Perzeptronen scheitern.', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}),\n",
              " Document(page_content='anschließende Versuche besser zu steuern und somit mögliche Sackgassen in der Lösungsfindung frühzeitig zu verhindern.[17] Heute wird der Begriff jedoch vorwiegend im Zusammenhang mit künstlichen neuronalen Netzen verwendet und tauchte in diesem Kontext erstmals im Jahr 2000 auf, in der Veröffentlichung Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications von Igor Aizenberg und Kollegen.[18][19][20]', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}),\n",
              " Document(page_content='benutzten künstlichen neuronalen Netze sind wie das menschliche Gehirn gebaut, wobei die Neuronen wie ein Netz miteinander verbunden sind. Die erste Schicht des neuronalen Netzes, die sichtbare Eingangsschicht, verarbeitet eine Rohdateneingabe, wie beispielsweise die einzelnen Pixel eines Bildes. Die Dateneingabe enthält Variablen, die der Beobachtung zugänglich sind, daher „sichtbare Schicht“.[3]', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}),\n",
              " Document(page_content='Künstliche neuronale Netze (KNN) sind Modelle, deren Struktur von biologischen neuronalen Netzen, aus denen Tiergehirne bestehen, inspiriert wurde. Solche Modelle  können aus komplexen und scheinbar zusammenhanglosen Informationen lernen. Einige erfolgreiche Anwendungen sind Bilderkennung und Spracherkennung.', metadata={'source': 'Maschinelles_Lernen', 'title': 'Maschinelles Lernen – Wikipedia'})]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "retriever.invoke(\"Was ist ein Neuron?\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.063843Z",
          "start_time": "2023-12-22T21:35:21.961702Z"
        },
        "id": "c5f252f5874b4337",
        "outputId": "743770ca-442a-472a-e004-e07de64bb496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "c5f252f5874b4337"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dokumente zusammensetzen\n",
        "\n",
        "Wie wir sehen gibt der Retriever mehrere Texte zurück. Wir hängen diese Texte zusammen, so dass wir einen längeren Text erhalten, welchen wir direkt in das AI Modell geben können."
      ],
      "metadata": {
        "collapsed": false,
        "id": "f732965071cf449a"
      },
      "id": "f732965071cf449a"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Karl Steinbuchs Lernmatrix[12] war eines der ersten künstlichen neuronalen Netze, das aus mehreren Schichten von Lerneinheiten oder lernenden „Neuronen“ bestand. Damit war er einer der Wegbereiter des Deep Learning, bei dem es um tiefe neuronale Netze geht, die viele Aufgaben erlernen können, bei denen früheren einschichtige Perzeptronen scheitern.\\n\\nanschließende Versuche besser zu steuern und somit mögliche Sackgassen in der Lösungsfindung frühzeitig zu verhindern.[17] Heute wird der Begriff jedoch vorwiegend im Zusammenhang mit künstlichen neuronalen Netzen verwendet und tauchte in diesem Kontext erstmals im Jahr 2000 auf, in der Veröffentlichung Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications von Igor Aizenberg und Kollegen.[18][19][20]\\n\\nbenutzten künstlichen neuronalen Netze sind wie das menschliche Gehirn gebaut, wobei die Neuronen wie ein Netz miteinander verbunden sind. Die erste Schicht des neuronalen Netzes, die sichtbare Eingangsschicht, verarbeitet eine Rohdateneingabe, wie beispielsweise die einzelnen Pixel eines Bildes. Die Dateneingabe enthält Variablen, die der Beobachtung zugänglich sind, daher „sichtbare Schicht“.[3]\\n\\nKünstliche neuronale Netze (KNN) sind Modelle, deren Struktur von biologischen neuronalen Netzen, aus denen Tiergehirne bestehen, inspiriert wurde. Solche Modelle  können aus komplexen und scheinbar zusammenhanglosen Informationen lernen. Einige erfolgreiche Anwendungen sind Bilderkennung und Spracherkennung.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "format_docs(retriever.invoke(\"Was ist ein Neuron?\"))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.094446Z",
          "start_time": "2023-12-22T21:35:22.019469Z"
        },
        "id": "3a56c685c8ccd133",
        "outputId": "d1ac827b-e3ad-451f-ad06-e16d04d6083f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "id": "3a56c685c8ccd133"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt Template\n",
        "\n",
        "Wir geben im Prompt-Template eine eindeutige Anweisung, was der Chatbot tun soll. Nachfolgender Code erstellt ein Prompt-Template, welches den Chatbot anweist, eine Frage zu beantworten."
      ],
      "metadata": {
        "collapsed": false,
        "id": "4430e5c803e90ef3"
      },
      "id": "4430e5c803e90ef3"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Sie sind ein Assistent zur Beantwortung von Fragen. Beantworten Sie die Frage mit Hilfe der gegebenen Kontext-Informationen. Wenn Sie die Antwort nicht wissen, sagen Sie einfach, dass Sie es nicht wissen und erfinden Sie nichts. Verwenden Sie maximal drei Sätze und fassen Sie die Antwort kurz.\"),\n",
        "        (\"human\", \"Frage: {frage} \\nKontext-Informationen: {kontext}\\n\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.181238Z",
          "start_time": "2023-12-22T21:35:22.057202Z"
        },
        "id": "8a5dc12fe5275457"
      },
      "id": "8a5dc12fe5275457"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'System: Sie sind ein Assistent zur Beantwortung von Fragen. Beantworten Sie die Frage mit Hilfe der gegebenen Kontext-Informationen. Wenn Sie die Antwort nicht wissen, sagen Sie einfach, dass Sie es nicht wissen und erfinden Sie nichts. Verwenden Sie maximal drei Sätze und fassen Sie die Antwort kurz.\\nHuman: Frage: Gegebene Frage \\nKontext-Informationen: Gegebener Kontext\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "prompt_template.invoke({\"kontext\": \"Gegebener Kontext\", \"frage\": \"Gegebene Frage\"}).to_string()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.211032Z",
          "start_time": "2023-12-22T21:35:22.068871Z"
        },
        "id": "d73ebb9ce87e34d6",
        "outputId": "6ae4fbed-388a-4de2-cc9b-d8d04e5afd3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "d73ebb9ce87e34d6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LLM Modell\n",
        "\n",
        "Wir verwenden das LLM Modell von OpenAI, um die Frage zu beantworten. Dabei setzen wir die Temperatur auf 0, so dass wir eine präzisere Antwort erhalten."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7f886c80e6411693"
      },
      "id": "7f886c80e6411693"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=key)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.321457Z",
          "start_time": "2023-12-22T21:35:22.081006Z"
        },
        "id": "e3ea046ded151a29"
      },
      "id": "e3ea046ded151a29"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pipeline\n",
        "\n",
        "Wir setzen diese Bausteine nun in einer Pipeline zusammen. Nachfolgender Code erstellt eine Pipeline, welche basierend auf einer Frage die passendsten Texte findet und diese dem Chatbot übergibt. Der Chatbot gibt dann eine Antwort zurück."
      ],
      "metadata": {
        "collapsed": false,
        "id": "5d4f0e22b8090b05"
      },
      "id": "5d4f0e22b8090b05"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "outputs": [],
      "source": [
        "rag_chain = (\n",
        "    {\"kontext\": retriever | format_docs, \"frage\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:22.345593Z",
          "start_time": "2023-12-22T21:35:22.210152Z"
        },
        "id": "11089a51041eddc0"
      },
      "id": "11089a51041eddc0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir können die Pipeline nun verwenden, um eine Frage zu stellen und eine Antwort zu erhalten."
      ],
      "metadata": {
        "collapsed": false,
        "id": "994491cbf6ee6065"
      },
      "id": "994491cbf6ee6065"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep Learning bezieht sich auf die Verwendung von künstlichen neuronalen Netzwerken mit vielen Schichten, um komplexe Muster in Daten zu erkennen und zu lernen. Es ermöglicht die automatische Extraktion von Merkmalen auf verschiedenen Abstraktionsebenen, insbesondere in Bereichen wie Bilderkennung und Sprachverarbeitung.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "rag_chain.invoke(\"Was ist deep learning?\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:24.961001Z",
          "start_time": "2023-12-22T21:35:22.225955Z"
        },
        "id": "2a69408e7361ae70",
        "outputId": "6c25c802-0019-4a55-ef6d-8b9afad9472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "2a69408e7361ae70"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frage: Was ist ein neuronales Netzwerk?\n",
            "Ein künstliches neuronales Netzwerk besteht aus einer Gruppe von Knoten, die miteinander verbunden sind, ähnlich wie Neuronen im menschlichen Gehirn. Es kann komplexe Informationen verarbeiten und lernen, Aufgaben wie Bilderkennung und Spracherkennung durchzuführen. Karl Steinbuchs Lernmatrix war eines der ersten künstlichen neuronalen Netze.\n"
          ]
        }
      ],
      "source": [
        "frage = input(\"Frage: \")\n",
        "print(rag_chain.invoke(frage))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:35:46.723799Z",
          "start_time": "2023-12-22T21:35:24.952428Z"
        },
        "id": "42e864bda98b842b",
        "outputId": "bc6af383-bce2-4d1c-d272-25ec4e0d01c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "42e864bda98b842b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frage generieren"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2785c54a5d18a3de"
      },
      "id": "2785c54a5d18a3de"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [],
      "source": [
        "def get_random_dokument():\n",
        "    random_document = random.choice(list(datenbank.docstore._dict.items()))\n",
        "    return random_document"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:05.466995Z",
          "start_time": "2023-12-22T21:36:05.443106Z"
        },
        "id": "872aa4fd2d61036e"
      },
      "id": "872aa4fd2d61036e"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('7061e809-e1a6-4bfe-8e8d-4525e0cbdcd3',\n",
              " Document(page_content='Karl Steinbuchs Lernmatrix[12] war eines der ersten künstlichen neuronalen Netze, das aus mehreren Schichten von Lerneinheiten oder lernenden „Neuronen“ bestand. Damit war er einer der Wegbereiter des Deep Learning, bei dem es um tiefe neuronale Netze geht, die viele Aufgaben erlernen können, bei denen früheren einschichtige Perzeptronen scheitern.', metadata={'source': 'Deep_Learning', 'title': 'Deep Learning – Wikipedia'}))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "get_random_dokument()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:06.409547Z",
          "start_time": "2023-12-22T21:36:06.377642Z"
        },
        "id": "9d7ade70da6bb2f",
        "outputId": "ca746cde-d2fe-4e56-efdf-ac8ec30f7492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9d7ade70da6bb2f"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Sie sind ein Assistent zur Generierung von Fragen. Generieren Sie eine neue Frage basierend auf den gegebenen Kontext-Informationen. Die Frage muss sehr spezifisch zum Inhalt sein und darf nicht generell sein wie 'was kommt im Dokument vor'. Generieren Sie einen Satz für die Frage mit einem Fragezeichen am Ende. Machen Sie danach 5 Leerzeilen und geben Sie mit maximal zwei Sätzen eine Musterlösung an. Beispielsweise könnten für die Kontext-Informationen 'Real Madrid ist ein Fussball Club' der Output wie folgt aussehen: 'FRAGE: Was ist Real Madrid? \\n\\n\\n\\n\\nANTWORT: Real Madrid ist ein Fussball Club.'\"),\n",
        "        (\"human\", \"Kontext-Informationen: {kontext}\\n\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:06.942216Z",
          "start_time": "2023-12-22T21:36:06.908441Z"
        },
        "id": "488c0273f96fe7c"
      },
      "id": "488c0273f96fe7c"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7, openai_api_key=key)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:08.002092Z",
          "start_time": "2023-12-22T21:36:07.861237Z"
        },
        "id": "7324337286d858c3"
      },
      "id": "7324337286d858c3"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "outputs": [],
      "source": [
        "frage_chain = (\n",
        "    {\"kontext\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:08.501277Z",
          "start_time": "2023-12-22T21:36:08.477269Z"
        },
        "id": "d287caba7fd9bd34"
      },
      "id": "d287caba7fd9bd34"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FRAGE: Wer hat seit 1997 den vorwärtsgerichteten hierarchisch-konvolutionalen Ansatz durch seitliche und rückwärtsgerichtete Verbindungen erweitert?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ANTWORT: Sven Behnke hat seit 1997 in der Neuronalen Abstraktionspyramide den vorwärtsgerichteten hierarchisch-konvolutionalen Ansatz durch seitliche und rückwärtsgerichtete Verbindungen erweitert.\n"
          ]
        }
      ],
      "source": [
        "print(frage_chain.invoke(get_random_dokument()[1].page_content))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-22T21:36:13.820803Z",
          "start_time": "2023-12-22T21:36:10.199355Z"
        },
        "id": "40dbe0cb3fc5eba7",
        "outputId": "75b25262-7932-4efc-bb25-ced2eb1b9773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "40dbe0cb3fc5eba7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-12-22T21:34:14.143301Z"
        },
        "id": "c2cae878d3b3ba0b"
      },
      "id": "c2cae878d3b3ba0b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}